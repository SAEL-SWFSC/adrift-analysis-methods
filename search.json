[
  {
    "objectID": "content/DataArchive/DataQualityCheck.html",
    "href": "content/DataArchive/DataQualityCheck.html",
    "title": "Data Quality Check",
    "section": "",
    "text": "Scan for any errors or mistakes in the Deployment Details spreadsheet (hydrophone, array, recorder, GPS, dates, etc.)\nReach out to deployment/retrieval team for corrections if needed",
    "crumbs": [
      "Data Archive",
      "Data Quality Check"
    ]
  },
  {
    "objectID": "content/DataArchive/DataQualityCheck.html#deployment-details-quality-check",
    "href": "content/DataArchive/DataQualityCheck.html#deployment-details-quality-check",
    "title": "Data Quality Check",
    "section": "",
    "text": "Scan for any errors or mistakes in the Deployment Details spreadsheet (hydrophone, array, recorder, GPS, dates, etc.)\nReach out to deployment/retrieval team for corrections if needed",
    "crumbs": [
      "Data Archive",
      "Data Quality Check"
    ]
  },
  {
    "objectID": "content/DataArchive/DataQualityCheck.html#check-recording-time-utc-vs-local-time",
    "href": "content/DataArchive/DataQualityCheck.html#check-recording-time-utc-vs-local-time",
    "title": "Data Quality Check",
    "section": "Check Recording Time: UTC vs Local Time",
    "text": "Check Recording Time: UTC vs Local Time\n\nCheck log files from extraced SUD files for Soundtrap Recording time (UTC vs Local Time), fix if needed\nOpen Taiki’s soundtrapRenamer script and run it to load all necessary functions\nRun the following code in a new script to check if the files were offloaded in UTC or local time\n\n\nsource('soundtrapRenamer.R')\n\n# change this to whatever file endings you want to change\nsuffixes &lt;- c('wav', 'sud', 'log.xml', 'accel.csv')\n\n# Change this to whatever folder these files are in\ndir &lt;- '../Data/Renamer/orig/'\n\nprep &lt;- prepTzFix(dir, offset=NULL, suffix=suffixes)\n\n\nIf the ‘prep’ output indicates that the files are on local time, run the following line of code to rename them\n\n\nfixStTz(dir, prep)\n\n\nIf files are renamed, the code will create a log file in the same folder of all of the name changes it made\nThere is also a reverse option that you can set to TRUE if you want to undo the renaming",
    "crumbs": [
      "Data Archive",
      "Data Quality Check"
    ]
  },
  {
    "objectID": "content/DataArchive/DataQualityCheck.html#assess-data-quality",
    "href": "content/DataArchive/DataQualityCheck.html#assess-data-quality",
    "title": "Data Quality Check",
    "section": "Assess Data Quality",
    "text": "Assess Data Quality\n\nScan the LTSA and define overall deployment as good, compromised, or unusable\nRecord Data Quality in Deployment Details spreadsheet",
    "crumbs": [
      "Data Archive",
      "Data Quality Check"
    ]
  },
  {
    "objectID": "content/DataArchive/DataQualityCheck.html#run-data-check-on-gps-data",
    "href": "content/DataArchive/DataQualityCheck.html#run-data-check-on-gps-data",
    "title": "Data Quality Check",
    "section": "Run Data Check on GPS Data",
    "text": "Run Data Check on GPS Data\n\nReview drift tracks created by Driftwatch\nLook at the image that is associated with the drift number and ensure all points are from the drift (no points from when the array was on the boat or land)",
    "crumbs": [
      "Data Archive",
      "Data Quality Check"
    ]
  },
  {
    "objectID": "content/DataArchive/DataQualityCheck.html#run-recording-qaqc",
    "href": "content/DataArchive/DataQualityCheck.html#run-recording-qaqc",
    "title": "Data Quality Check",
    "section": "Run Recording QAQC ",
    "text": "Run Recording QAQC \n\nsoundtrapQAQC function in PAMmisc\nMatlab QAQC script\nIf the QAQC shows significant gaps in the files (i.e. &gt;1 second), complete the following steps to account for those gaps\n\nIf you have a gap in the middle of the drift (with significant amount of data before AND after the gap) continue on with the following steps and add a readMe to the data folder indicating when and how long the gap is\nIf you have duty cylced recordings at the end of a continuous recording period, cut off the data",
    "crumbs": [
      "Data Archive",
      "Data Quality Check"
    ]
  },
  {
    "objectID": "content/DataArchive/DataQualityCheck.html#scan-ltsa-for-noisy-data",
    "href": "content/DataArchive/DataQualityCheck.html#scan-ltsa-for-noisy-data",
    "title": "Data Quality Check",
    "section": "Scan LTSA for Noisy Data",
    "text": "Scan LTSA for Noisy Data\nIf drift has been determined to be compromised in the data quality check above, scan the LTSA to log time periods with noisy/compromised data\n\nUse the LTSA created with 500 Hz wav files, with 1s and 5Hz parameters\nView LTSA at 2 hour windows and scan through\nUse Logger to define start/end times of the noisy/bad data and include the type of noise in the comments (e.g. strumming, impulses, etc.)\nSplit between Anne and Cory",
    "crumbs": [
      "Data Archive",
      "Data Quality Check"
    ]
  },
  {
    "objectID": "content/DataArchive/TethysDeployments.html",
    "href": "content/DataArchive/TethysDeployments.html",
    "title": "Tethys - Deployments",
    "section": "",
    "text": "Combine deployment details with GPS data in Tethys format\nFollow guidelines on the TethysSAEL repository on Anne’s github (requires inputs from deployment details worksheet and GPS csv files)",
    "crumbs": [
      "Data Archive",
      "Archive",
      "Tethys - Deployments"
    ]
  },
  {
    "objectID": "content/DataArchive/TethysDeployments.html#create-deployment-worksheet",
    "href": "content/DataArchive/TethysDeployments.html#create-deployment-worksheet",
    "title": "Tethys - Deployments",
    "section": "",
    "text": "Combine deployment details with GPS data in Tethys format\nFollow guidelines on the TethysSAEL repository on Anne’s github (requires inputs from deployment details worksheet and GPS csv files)",
    "crumbs": [
      "Data Archive",
      "Archive",
      "Tethys - Deployments"
    ]
  },
  {
    "objectID": "content/DataArchive/TethysDeployments.html#deployment-details-to-tethys",
    "href": "content/DataArchive/TethysDeployments.html#deployment-details-to-tethys",
    "title": "Tethys - Deployments",
    "section": "Deployment details to Tethys",
    "text": "Deployment details to Tethys\n\nUpload finalized deployment details to Tethys using appropriate sourcemap\n\nMobile and moored deployment sourcemaps in TethysSAEL repository on Anne’s github\n\nWork with Anne for this",
    "crumbs": [
      "Data Archive",
      "Archive",
      "Tethys - Deployments"
    ]
  },
  {
    "objectID": "content/DataArchive/TethysDeployments.html#pampaltethys-metadata",
    "href": "content/DataArchive/TethysDeployments.html#pampaltethys-metadata",
    "title": "Tethys - Deployments",
    "section": "PAMpal/Tethys Metadata",
    "text": "PAMpal/Tethys Metadata\n\nTalk w/ Taiki about how to enter/store this metadata (we discussed having a function that saves it to a csv so it can be uploaded to Pampal and Tethys). This will include info needed for Passive Packer. \nAdditional comments on workflow spreadsheet",
    "crumbs": [
      "Data Archive",
      "Archive",
      "Tethys - Deployments"
    ]
  },
  {
    "objectID": "content/DataArchive/DataPrep.html",
    "href": "content/DataArchive/DataPrep.html",
    "title": "Data Prep",
    "section": "",
    "text": "Check that all columns in the Deployment Details spreadsheet are completed\nReach out to deployment/retrieval team for additional deployment details if needed",
    "crumbs": [
      "Data Archive",
      "Data Prep"
    ]
  },
  {
    "objectID": "content/DataArchive/DataPrep.html#complete-data-entries",
    "href": "content/DataArchive/DataPrep.html#complete-data-entries",
    "title": "Data Prep",
    "section": "",
    "text": "Check that all columns in the Deployment Details spreadsheet are completed\nReach out to deployment/retrieval team for additional deployment details if needed",
    "crumbs": [
      "Data Archive",
      "Data Prep"
    ]
  },
  {
    "objectID": "content/DataArchive/DataPrep.html#sud-file-extraction",
    "href": "content/DataArchive/DataPrep.html#sud-file-extraction",
    "title": "Data Prep",
    "section": "SUD File Extraction",
    "text": "SUD File Extraction\nExtract SUD files using the Soundtrap Host Software\n\nOpen the Soundtrap Host Software and navigate to Tools &gt; Set Default File Save Location\nBrowse to the folder where the SUD files are saved and select it\nNavigate again to Tools &gt; File Extraction\nClick Select File, navigate to the SUD file folder, select all, and click open\nSUD file extraction will begin, take note of the number of files and ensure this is equal to the number of extracted files once the process is completed",
    "crumbs": [
      "Data Archive",
      "Data Prep"
    ]
  },
  {
    "objectID": "content/DataArchive/DataPrep.html#generate-full-bandwidth-ltsa",
    "href": "content/DataArchive/DataPrep.html#generate-full-bandwidth-ltsa",
    "title": "Data Prep",
    "section": "Generate Full Bandwidth LTSA",
    "text": "Generate Full Bandwidth LTSA\nUsing Triton on Matlab, generate a full bandwidth LTSA with the wav files from the SUD files previously extracted\n\nOpen Matlab and type Triton into the command window\nThree Triton windows will open, using the Control window, navigate to Tools &gt; Make LTSA from Directory of Files\nSelect File Type pop up will open, select 1 for wav files (enter 2 or 3 if working with other sound file type)\nUsing the file explorer pop up, navigate to folder where wav files are stored and click Select Folder\nThe Set Long-Term Spectrogram Parameters window will open, set the Time Average Length to 5 seconds and the Frequency Bin Size to 200 Hz, press enter\nThe Choose Channel to LTSA window will open, select 1 and press OK\nThe Save LTSA File window will open, navigate to desired folder, name the output file using this format: ADRIFT_###_5s_200Hz.ltsa, and press save\nThe LTSA will begin to process and will automatically open in the plot window once completed",
    "crumbs": [
      "Data Archive",
      "Data Prep"
    ]
  },
  {
    "objectID": "content/DataArchive/DataPrep.html#identify-recording-data-start-and-data-end",
    "href": "content/DataArchive/DataPrep.html#identify-recording-data-start-and-data-end",
    "title": "Data Prep",
    "section": "Identify Recording Data Start and Data End",
    "text": "Identify Recording Data Start and Data End\n\nUsing the LTSA, identify when the data starts in the recordings (usually determined by when there is no ship noise from the deployment present in LTSA)\nIdentify when the data ends in the LTSA (right before retrieval ship noise is present)\nTruncate the data by deleting the recordings outside of that time range",
    "crumbs": [
      "Data Archive",
      "Data Prep"
    ]
  },
  {
    "objectID": "content/DataArchive/DataPrep.html#update-deployment-details",
    "href": "content/DataArchive/DataPrep.html#update-deployment-details",
    "title": "Data Prep",
    "section": "Update deployment details ",
    "text": "Update deployment details \n\nInput Data Start and Data End times into the Deployment Details spreadsheet using the Data Start/End times determined above",
    "crumbs": [
      "Data Archive",
      "Data Prep"
    ]
  },
  {
    "objectID": "content/DataArchive/Permits.html",
    "href": "content/DataArchive/Permits.html",
    "title": "Permits",
    "section": "",
    "text": "Review sightings/takes forms and record takes in the Deployment Details spreadsheet\nAdditional guidelines and information can be found in the Protected Resources Permit",
    "crumbs": [
      "Data Archive",
      "Permits"
    ]
  },
  {
    "objectID": "content/DataArchive/Permits.html#noaa-protected-resources-permit",
    "href": "content/DataArchive/Permits.html#noaa-protected-resources-permit",
    "title": "Permits",
    "section": "",
    "text": "Review sightings/takes forms and record takes in the Deployment Details spreadsheet\nAdditional guidelines and information can be found in the Protected Resources Permit",
    "crumbs": [
      "Data Archive",
      "Permits"
    ]
  },
  {
    "objectID": "content/DataArchive/Permits.html#noaa-sanctuary-permit",
    "href": "content/DataArchive/Permits.html#noaa-sanctuary-permit",
    "title": "Permits",
    "section": "NOAA Sanctuary Permit",
    "text": "NOAA Sanctuary Permit\n\nReview the SanctuarySummary spreadsheet from Driftwatch and check for Sanctuary overlap\nRecord which sanctuaries the drift passed through in the Sanctuary Permit column in the Deployment Details spreadsheet\nAdditional guidelines and information can be found in the Sanctuary Permit",
    "crumbs": [
      "Data Archive",
      "Permits"
    ]
  },
  {
    "objectID": "content/DataArchive/Permits.html#permit-spreadsheet",
    "href": "content/DataArchive/Permits.html#permit-spreadsheet",
    "title": "Permits",
    "section": "Permit Spreadsheet",
    "text": "Permit Spreadsheet\nRecord all other permit related information in the Permit Spreadsheet including take numbers and sanctuary overlap",
    "crumbs": [
      "Data Archive",
      "Permits"
    ]
  },
  {
    "objectID": "content/Slides/methodsSlidesTemplate.html#title-page",
    "href": "content/Slides/methodsSlidesTemplate.html#title-page",
    "title": "Methods Template",
    "section": "Title Page",
    "text": "Title Page\nThis template can be used to create slides for your analysis methods\nEdit the text and link in the footer above to redirect to your main methods page\nSee Quarto’s Revealjs documentation and options pages for more information on formatting and editing your slides\nFor advanced formatting options see Quarto’s Advanced Reveal documentation"
  },
  {
    "objectID": "content/Slides/methodsSlidesTemplate.html#new-slide",
    "href": "content/Slides/methodsSlidesTemplate.html#new-slide",
    "title": "Methods Template",
    "section": "New Slide",
    "text": "New Slide\nNew slides can be created using the header options\n\n‘## Slide Title’ creates a new slide\n‘# Slide Title’ creates a new section with a title slide\nSee following slides for example"
  },
  {
    "objectID": "content/Slides/methodsSlidesTemplate.html#new-slide-in-section",
    "href": "content/Slides/methodsSlidesTemplate.html#new-slide-in-section",
    "title": "Methods Template",
    "section": "New Slide in Section",
    "text": "New Slide in Section\nThe outline can be viewed by clicking the three lines in the bottom left corner in the rendered slides"
  },
  {
    "objectID": "content/Slides/methodsSlidesTemplate.html#multiple-columns",
    "href": "content/Slides/methodsSlidesTemplate.html#multiple-columns",
    "title": "Methods Template",
    "section": "Multiple Columns",
    "text": "Multiple Columns\nYou can add text and images side by side using columns\nEdit the number of columns and column width as needed\n\n\nLeft column\n\nText\n\n\nRight column"
  },
  {
    "objectID": "content/Slides/methodsSlidesTemplate.html#absolute-positions",
    "href": "content/Slides/methodsSlidesTemplate.html#absolute-positions",
    "title": "Methods Template",
    "section": "Absolute Positions",
    "text": "Absolute Positions\nPosition images or other elements at precise locations using class .absolute"
  },
  {
    "objectID": "content/Slides/methodsSlidesTemplate.html#content-overflow",
    "href": "content/Slides/methodsSlidesTemplate.html#content-overflow",
    "title": "Methods Template",
    "section": "Content Overflow",
    "text": "Content Overflow\nHere are some ways to deal with too much information on one slide\n\nUse the .smaller class to use a smaller typeface\nUse the .scrollable class to make off-slide content available by scrolling"
  },
  {
    "objectID": "content/Slides/methodsSlidesTemplate.html#content-overflow-.smaller",
    "href": "content/Slides/methodsSlidesTemplate.html#content-overflow-.smaller",
    "title": "Methods Template",
    "section": "Content Overflow: .smaller",
    "text": "Content Overflow: .smaller\nHere’s the smaller font"
  },
  {
    "objectID": "content/Slides/methodsSlidesTemplate.html#content-overflow-.scrollable",
    "href": "content/Slides/methodsSlidesTemplate.html#content-overflow-.scrollable",
    "title": "Methods Template",
    "section": "Content Overflow: .scrollable",
    "text": "Content Overflow: .scrollable\nHere you can scroll down the slide\n\nList a\nList b\nList c\nList d\nList e\nList f\nList g\nList h\nList i\nList j"
  },
  {
    "objectID": "content/Slides/methodsSlidesTemplate.html#adding-code-to-slides",
    "href": "content/Slides/methodsSlidesTemplate.html#adding-code-to-slides",
    "title": "Methods Template",
    "section": "Adding Code To Slides",
    "text": "Adding Code To Slides\nYou can add code blocks and executable code to your slides. There are a wide variety of options to customize and display code, see the following resources for guidance\n\nHTML Code Blocks\nRevealjs Code Options"
  },
  {
    "objectID": "content/Slides/methodsSlidesTemplate.html#text-and-image-side-by-side",
    "href": "content/Slides/methodsSlidesTemplate.html#text-and-image-side-by-side",
    "title": "Methods Template",
    "section": "Text and Image Side by Side",
    "text": "Text and Image Side by Side\n\n\n\nCurrently we are using Matlab 2021b\nOn the home tab -&gt; Environment -&gt; Set Path\nClick “Add folder with Subfolders…”\nBrowse to the folder containing Triton-R2020 (or the newest version of Triton on GitHub)\nClick ‘Save’ and then ’Close"
  },
  {
    "objectID": "content/Slides/methodsSlidesTemplate.html#slide-with-multiple-columns",
    "href": "content/Slides/methodsSlidesTemplate.html#slide-with-multiple-columns",
    "title": "Methods Template",
    "section": "Slide with Multiple Columns",
    "text": "Slide with Multiple Columns\n\n\n\nStart Matlab and at the command prompt type ‘triton’ and press enter to run the application\nThree windows will be displayed:\n\nPlot\nControl\nMessage\n\n\n\n\n\nControl Window - Controls settings for Plot Window\nMessage Window - Keeps a record of the users actions and displays Plot Window cursor location\n\n\n\n\nPlot Window - Displays Long Term Spectral Average (LTSA), spectrogram, spectra, and time series plots"
  },
  {
    "objectID": "content/Slides/methodsSlidesTemplate.html#slide-with-scrollable-figure-panel",
    "href": "content/Slides/methodsSlidesTemplate.html#slide-with-scrollable-figure-panel",
    "title": "Methods Template",
    "section": "Slide with Scrollable Figure Panel",
    "text": "Slide with Scrollable Figure Panel\n\n\n\n\n\n\nSNR 1 Call\n\n\n\n\n\n\n\nSNR 2 Call\n\n\n\n\n\n\n\n\n\nSNR 3 Call\n\n\n\n\n\n\n\nBad Recordings"
  },
  {
    "objectID": "content/Slides/methodsSlidesTemplate.html#slide-with-code",
    "href": "content/Slides/methodsSlidesTemplate.html#slide-with-code",
    "title": "Methods Template",
    "section": "Slide with Code",
    "text": "Slide with Code\n\nlibrary(ggplot2)\nggplot(mtcars, aes(hp, mpg, color = am)) +\n  geom_point() +\n  geom_smooth(formula = y ~ x, method = \"loess\")"
  },
  {
    "objectID": "content/Slides/methodsSlidesTemplate.html#slide-with-executable-code",
    "href": "content/Slides/methodsSlidesTemplate.html#slide-with-executable-code",
    "title": "Methods Template",
    "section": "Slide with Executable Code",
    "text": "Slide with Executable Code\n\n#library(ggplot2)\n#ggplot(mtcars, aes(hp, mpg, color = am)) +\n#  geom_point() +\n#  geom_smooth(formula = y ~ x, method = \"loess\")"
  },
  {
    "objectID": "content/Slides/methodsSlidesTemplate.html#slide-with-highlighted-code-lines",
    "href": "content/Slides/methodsSlidesTemplate.html#slide-with-highlighted-code-lines",
    "title": "Methods Template",
    "section": "Slide with Highlighted Code Lines",
    "text": "Slide with Highlighted Code Lines\nlibrary(ggplot2)\nggplot(mtcars, aes(hp, mpg, color = am)) +\n  geom_point() +\n  geom_smooth(formula = y ~ x, method = \"loess\")\n\nMore line highlighting options here\n\n\n\n\nSource Code"
  },
  {
    "objectID": "content/Soundscapes/Metrics.html",
    "href": "content/Soundscapes/Metrics.html",
    "title": "Triton Metrics",
    "section": "",
    "text": "Soundscape methods are aligned with SanctSound protocols as much as possible (https://sanctsound.ioos.us/)\nTriton software is used for the following:\n\nAcoustic data is decimated to 48 kHz sample rate\nSoundscape long-term spectral averages (LTSAs) are calculated with a 1 Hz, 1 second resolution\nThe full system calibration value is calculated from the combined hydrophone and Sound Trap sensitivity\nSoundscape LTSAs are used to calculate sound levels in 2 minute windows from 100-24,000 Hz, including broadband sound pressure levels, third-octave levels, and power spectral densities. Median (50th percentile), mean, and various statistical sound levels (1st, 5th, 10th,25th, 75th, 90th, 95th percentiles) are calculated for each metric.\nVessels are detected by manually scanning LTSAs with X Hz, X s resolution in 1 hour windows\nIdentify periods of noisy or bad data to eliminate from downstream analyses\n\nSoundscape metrics are only calculated for drifts that used a Soundtrap model 4300 or 640 with a HTI-92WB hydrophone. In the 2016 PASCAL project, there were 13 drifts that either used a SM2, SM3 recorder, or included an array that only had HTI-96min hydrophones. These drifts do not have soundscape metrics.",
    "crumbs": [
      "Soundscapes",
      "Triton Metrics"
    ]
  },
  {
    "objectID": "content/Soundscapes/Metrics.html#methods-summary",
    "href": "content/Soundscapes/Metrics.html#methods-summary",
    "title": "Triton Metrics",
    "section": "",
    "text": "Soundscape methods are aligned with SanctSound protocols as much as possible (https://sanctsound.ioos.us/)\nTriton software is used for the following:\n\nAcoustic data is decimated to 48 kHz sample rate\nSoundscape long-term spectral averages (LTSAs) are calculated with a 1 Hz, 1 second resolution\nThe full system calibration value is calculated from the combined hydrophone and Sound Trap sensitivity\nSoundscape LTSAs are used to calculate sound levels in 2 minute windows from 100-24,000 Hz, including broadband sound pressure levels, third-octave levels, and power spectral densities. Median (50th percentile), mean, and various statistical sound levels (1st, 5th, 10th,25th, 75th, 90th, 95th percentiles) are calculated for each metric.\nVessels are detected by manually scanning LTSAs with X Hz, X s resolution in 1 hour windows\nIdentify periods of noisy or bad data to eliminate from downstream analyses\n\nSoundscape metrics are only calculated for drifts that used a Soundtrap model 4300 or 640 with a HTI-92WB hydrophone. In the 2016 PASCAL project, there were 13 drifts that either used a SM2, SM3 recorder, or included an array that only had HTI-96min hydrophones. These drifts do not have soundscape metrics.",
    "crumbs": [
      "Soundscapes",
      "Triton Metrics"
    ]
  },
  {
    "objectID": "content/Soundscapes/Metrics.html#step-by-step-instructions",
    "href": "content/Soundscapes/Metrics.html#step-by-step-instructions",
    "title": "Triton Metrics",
    "section": "Step-by-Step Instructions",
    "text": "Step-by-Step Instructions\n\nDecimation of acoustic data\nMost ADRIFT acoustic data is recorded at sampling rates of 384 kHz, however soundscape metrics are only calculated up to 24 kHz. To reduce processing time and data storage requirements, full bandwidth data is decimated to a sample rate of 48 kHz using a decimation factor of 8 (384,000/48,000=8).\n\nUsing the Tools menu in the Triton “Control” window, choose to decimate an entire folder of WAV files\n\nYou will be prompted to choose a folder of WAV files, and then define the appropriate decimation factor. For example, to decimate from 384 kHz to 48 kHz, use a decimation factor of 8.\nThen define a folder to save the new, decimated WAV files.\nThe decimation process will start automatically and show a progress bar. When the decimation is complete, the progress bar will disappear. Depending on the total number of files and the required decimation factor, this process may take a few hours.\n\n\n\nGenerate soundscape LTSA\n\nAdd the soundscape remora to Triton (see Remoras menu in “Control” window), if it hasn’t already been added. Triton will need to be restarted after adding the remora for the first time.\nUsing the Remoras menu in the Triton “Control” window, choose to Make Soundscape LTSAs\n\nDefine the appropriate settings to generate the soundscape LTSA, including:\n\nInput directory containing 48kHz WAV files\nOutput directory to save LTSA files\nOutput filename\nAveraging Time [s]=1, Frequency bin size [Hz]=1, Length of LTSA [days]=3, Start with LTSA#=1, File type=1, Data Type=5, Data Channel Number=1\nPress Run Soundscape LTSA\n\n\nThe LTSA generation process will start automatically and show a progress bar. When the LTSA is complete, it will load automatically. Do not be concerned if the LTSA looks strange. Soundscape LTSAs must be loaded with the Soundscape Remora to be properly viewed. This process may take a few hours.\n\n\n\nCalculate full system calibration\nThe full system calibration value is calculated by the hydrophone and recorder sensitivity, both of which should be provided by the manufacturer. SoundTrap recorder sensitivities are available on the OceanInstruments website, and should be reported in units of “dB”. Hydrophone sensitivities should be reported in units of “dB re: 1V/uPa”. For example, for a HTI-96min hydrophone with sensitivity of -155 dB re: 1V/uPa, and a ST640 SoundTrap with sensitivity of -4 dB, the full system calibration value would be -159 dB e: 1V/uPa.\nSee ‘SysSens’ function to automatically find calibration value for each deployment based on the deployment details and inventory worksheets. While hydrophone and recorder sensitivities are generally reported as negative values, the calibration value provided to Triton should be the absolute value of the combined sensitivities (a positive value).\n\n\nCalculate soundscape metrics\n\nUsing the Remoras menu in the Triton “Control” window, choose to Compute Soundscape Metrics\n\nDefine the appropriate settings to generate the soundscape metrics, including:\n\nDirectory with LTSA(s)\nOutput Directory for metrics\nInput Start file\nLow Frequency Limit [Hz]=100, High Frequency Limit [Hz]=24000, Bin Size Time [sec]=120, PSD Bin Size Frequency [Hz]=1, Min. Seconds/Average[%]=50\nCheck boxes for Broadband Level, Third Octave Level, and Power Spectral Density\nCheck boxes for Mean, Median, and Percentiles\nCheck box for Calibration, and insert appropriate calibration value\n\n\n\nADRIFT recordings were collected on a continuous or 50% duty cycle (6 min on out of every 12 minutes). Carious duty cycles were used to collect acoustic data from the 2016 PASCAL and 2018 CCES survey, with a minimum 2-minute recording time. Therefore, a 2 minute window is used to calculate soundscape metrics which can be compared across surveys.\nConsistent cable strumming was observed below 100 Hz on many drifting buoy deployments, therefore the lower frequency limit for all calculated soundscape metrics was set to 100 Hz.\n\n\nDetect vessels\n\nStart Triton Logger Remora\n1. Launch Triton within Matlab. Open the LTSA for the data you want to analyze.\n2. In the Triton “Control” window, select the Remoras menu, choose Logger and then start a new log. You will need to re-start Triton if this is the first instance of using the Logger remora. See more info on Triton Remoras on the Marine Bioacoustic Research Collective wiki.\n\n\nLog start and end time of ship acoustic events\nShips produce different noises such as impulsive signals from ship propeller cavitation or echosounder signals that can be easily identified in the LTSA and confirmed with the spectrogram. \nA trained analyst viewed 1 h windows of long-term spectral averages (LTSA; Wiggins and Hildebrand (2007); 5 s time average, 100 Hz frequency bins). Once a ship was identified, 10 s spectrograms were used to confirm identification (Fast Fourier transform length 2000 points, 75% overlap). Both LTSAs and spectrograms were scanned with a brightness of 60 and a contrast of 180 for consistency across deployments. Ships were either logged as being broadband (Figure 1) or narrowband/low frequency (Figure 2). Narrowband/low frequency ship signals were fainter while broadband signals were high amplitude and had frequency content above 5kHz during the vessel’s passage.\nWe assumed no signals were mistaken for ships because all LTSA detections were visually verified. We also assumed negligible missed detections of high amplitude ships given the characteristics of ships that make them easy to distinguish.\n\n\n\n\n\n\nFigure 1: Example of a broadband ship in the 1 hr LTSA (top) and 10 s spectrogram (bottom).\n\n\n\n\n\n\n\n\n\nFigure 2: Example of a narrowband/low frequency ship in the 1 hr LTSA (top; red box) and 10 s spectrogram (bottom).\n\n\n\n\n\n\nIdentify time periods of bad data\nScan LTSA (1s, 1 Hz resolution) with 2-hour windows, viewing frequencies between 0-500 Hz to identify time periods with noisy or compromised data quality. This review was performed as part of the initial data quality check (see more details on these methods here), and is an important step to identify time periods where noisy data prevents accurate calculations of sound levels in the environment.",
    "crumbs": [
      "Soundscapes",
      "Triton Metrics"
    ]
  },
  {
    "objectID": "content/ToothedWhales/NBHF-BANTER.html",
    "href": "content/ToothedWhales/NBHF-BANTER.html",
    "title": "NBHF - BANTER",
    "section": "",
    "text": "Pamguard v.2.02 is used to run click detector \nAcoustic data is sampled with minimum sample rate 384 kHz\nData is high-pass filtered at 100 kHz  with a single click detector (12 dB threshold) \nEvents are manually defined in Pamguard Viewer\nPAMpal is used to calculate features of click detections in each event"
  },
  {
    "objectID": "content/ToothedWhales/NBHF-BANTER.html#methods-summary",
    "href": "content/ToothedWhales/NBHF-BANTER.html#methods-summary",
    "title": "NBHF - BANTER",
    "section": "",
    "text": "Pamguard v.2.02 is used to run click detector \nAcoustic data is sampled with minimum sample rate 384 kHz\nData is high-pass filtered at 100 kHz  with a single click detector (12 dB threshold) \nEvents are manually defined in Pamguard Viewer\nPAMpal is used to calculate features of click detections in each event"
  },
  {
    "objectID": "content/ToothedWhales/Dolphins-Detection.html",
    "href": "content/ToothedWhales/Dolphins-Detection.html",
    "title": "Dolphins",
    "section": "",
    "text": "Identified dolphin acoustic events include echolocation clicks from Risso’s and Pacific white-sided dolphins, and whistles from unidentified dolphin species\nTriton software is used for the following:\n\nLong-term spectral averages (LTSAs) are calculated with a 200 Hz, 5 second resolution\nFor continuous recordings (ADRIFT dataset), the start and end times of dolphin acoustic events are identified by manually scanning LTSAs in 1 hour windows\nFor duty-cycled recordings (CCES and PASCAL datasets), the presence of dolphin acoustic events is identified within 2-minute bins",
    "crumbs": [
      "Toothed Whales",
      "Dolphins"
    ]
  },
  {
    "objectID": "content/ToothedWhales/Dolphins-Detection.html#methods-summary",
    "href": "content/ToothedWhales/Dolphins-Detection.html#methods-summary",
    "title": "Dolphins",
    "section": "",
    "text": "Identified dolphin acoustic events include echolocation clicks from Risso’s and Pacific white-sided dolphins, and whistles from unidentified dolphin species\nTriton software is used for the following:\n\nLong-term spectral averages (LTSAs) are calculated with a 200 Hz, 5 second resolution\nFor continuous recordings (ADRIFT dataset), the start and end times of dolphin acoustic events are identified by manually scanning LTSAs in 1 hour windows\nFor duty-cycled recordings (CCES and PASCAL datasets), the presence of dolphin acoustic events is identified within 2-minute bins",
    "crumbs": [
      "Toothed Whales",
      "Dolphins"
    ]
  },
  {
    "objectID": "content/ToothedWhales/Dolphins-Detection.html#step-by-step-instructions",
    "href": "content/ToothedWhales/Dolphins-Detection.html#step-by-step-instructions",
    "title": "Dolphins",
    "section": "Step-by-Step Instructions",
    "text": "Step-by-Step Instructions\n\nGenerate Long Term Spectral Average (LTSA)\nSee methods in “Data Prep” section. Use 5 s 200 Hz resolution.\n\n\nStart Triton Logger Remora\n\nLaunch Triton within Matlab. Open the LTSA for the data you want to analyze.\nIn the Triton “Control” window, select the Remoras menu, choose Logger and then start a new log. You will need to re-start Triton if this is the first instance of using the Logger remora. See more info on Triton Remoras on the Marine Bioacoustic Research Collective wiki.\n\n\n\nAnnotate the presence dolphin acoustic events\nRisso's dolphins (Grampus griseus) and Pacific white-sided dolphins (Lagenorhynchus obliquidens) produce echolocation clicks which can be identified to species by distinct spectral features observable in the LTSA and spectrogram (Soldevilla et al. 2008). There is some varation in the spectral features of echolocation clicks for Risso’s dolphins (Soldevilla et al. 2017) and Pacific white-sided dolphins (Soldevilla et al. 2008). The analysts noted the presence of different click types within each encounter, when possible. Some dolphin species produce echolocation clicks which cannot currently be classified from the LTSA; those species are not included in this analysis, but their presence may be captured by the dolphin whistle events.\n[INSERT SCREENSHOT SHOWING START AND END TIME OF RISSO’S DOLPHIN ECHOLOCATION EVENT]\n[INSERT SCREENSHOT SHOWING START AND END TIME OF PACIFIC WHITE-SIDED DOLPHIN ECHOLOCATION EVENT]\n&lt;!--# Potential unidentified dolphin species within the California Current include common dolphins (Delphinus spp.), bottlenose dolphins (Tursiops truncatus), Northern right whale dolphin (Lissodelphus borealis), and striped dolphins (Stenella coeruleoalba).\n--&gt;\nDolphin whistles appear in the LTSA as scattered, yet distinct pockets of energy between 2-20 kHz. There are no established methods to identify dolphin species by their whistles in the LTSA alone; therefore dolphin whistle events are all attributed to “Unidentified Odontocetes”.\n[INSERT SCREENSHOT SHOWING START AND END TIME OF DOLPHIN WHISTLE EVENT]\nDolphin acoustic events are defined with an encounter granularity (including start and end time) for continuous acoustic data, and with a 2-minute binned granularity (presence-only within a 2-minute bin) for duty-cycled acoustic data.",
    "crumbs": [
      "Toothed Whales",
      "Dolphins"
    ]
  },
  {
    "objectID": "content/BaleenWhales/BlueWhales-ManualDetection.html",
    "href": "content/BaleenWhales/BlueWhales-ManualDetection.html",
    "title": "Blue Whales - Manual Detection",
    "section": "",
    "text": "Due to the low frequency noise that persisted under 50Hz throughout most of the drifts, manual logging of calls was the easiest option to bin blue whale vocalizations.\nTriton software was used to create and manually bin blue whale A,B and D calls into 60 minute bins.\n\nLogging methods can be found here.\n\nLogs were saved in excel and then compiled using R into one final worksheet.\nR was then used to bin blue whale presence into hourly presence plots"
  },
  {
    "objectID": "content/BaleenWhales/BlueWhales-ManualDetection.html#logging-a-b-and-d-calls-in-the-ltsa",
    "href": "content/BaleenWhales/BlueWhales-ManualDetection.html#logging-a-b-and-d-calls-in-the-ltsa",
    "title": "Blue Whales - Manual Detection",
    "section": "",
    "text": "Due to the low frequency noise that persisted under 50Hz throughout most of the drifts, manual logging of calls was the easiest option to bin blue whale vocalizations.\nTriton software was used to create and manually bin blue whale A,B and D calls into 60 minute bins.\n\nLogging methods can be found here.\n\nLogs were saved in excel and then compiled using R into one final worksheet.\nR was then used to bin blue whale presence into hourly presence plots"
  },
  {
    "objectID": "content/BaleenWhales/Slides/minkeMethods.html#overview",
    "href": "content/BaleenWhales/Slides/minkeMethods.html#overview",
    "title": "Minke Methods",
    "section": "Overview",
    "text": "Overview\nWithin PAMGuard, a Generalized Power Law detector was used to detect Minke boings. We started with basic GPL settings from Tyler Helble’s PARM files and modified them to fit our data.\n\nExample Pamguard settings file\n\n\nSpectrogram of Minke whale boings being detected by GPL detector"
  },
  {
    "objectID": "content/BaleenWhales/Slides/minkeMethods.html#database-binary-storage",
    "href": "content/BaleenWhales/Slides/minkeMethods.html#database-binary-storage",
    "title": "Minke Methods",
    "section": "Database & Binary Storage",
    "text": "Database & Binary Storage\n\nSet database path to a new blank database titled ADRIFT_###_PG_2_02_02_Minke.sqlite3\nCreate a new binary folder for your detections titled ADRIFT_###_PG_2_02_02_Minke"
  },
  {
    "objectID": "content/BaleenWhales/Slides/minkeMethods.html#hydrophone-array",
    "href": "content/BaleenWhales/Slides/minkeMethods.html#hydrophone-array",
    "title": "Minke Methods",
    "section": "Hydrophone Array",
    "text": "Hydrophone Array\nDepending on the drift that was processed, the array settings in Pamguard were updated to reflect the spacing between hydrophones and the hydrophone sensitivity. For our purposes we only used CH0 in Pamguard to run the detector (CH 1 in physical hydrophone array)."
  },
  {
    "objectID": "content/BaleenWhales/Slides/minkeMethods.html#sound-acquisition-decimation",
    "href": "content/BaleenWhales/Slides/minkeMethods.html#sound-acquisition-decimation",
    "title": "Minke Methods",
    "section": "Sound Acquisition & Decimation",
    "text": "Sound Acquisition & Decimation\n\nSet the sound acquisition path to the folder your sound files are in\nThe Decimator in PAMGuard was set to decimate to 10kHz and used a Butterworth Low Pass Filter of 5kHz."
  },
  {
    "objectID": "content/BaleenWhales/Slides/minkeMethods.html#gpl-settings",
    "href": "content/BaleenWhales/Slides/minkeMethods.html#gpl-settings",
    "title": "Minke Methods",
    "section": "GPL Settings",
    "text": "GPL Settings\n\n\n\n\n\nFFT Settings\n\n\n\n\n\n\n\n\nDetection Settings\n\n\n\n\n\n\n\n\nContours settings"
  },
  {
    "objectID": "content/BaleenWhales/Slides/minkeMethods.html#spectrogram-annotation-setup",
    "href": "content/BaleenWhales/Slides/minkeMethods.html#spectrogram-annotation-setup",
    "title": "Minke Methods",
    "section": "Spectrogram Annotation Setup",
    "text": "Spectrogram Annotation Setup\nIn order for PAMpal to interact with the GPL detections we added in the Detection Grouper Module. This allows PAMpal to create events and push them back in the SQLite database in PAMGuard."
  },
  {
    "objectID": "content/BaleenWhales/Slides/minkeMethods.html#detection-grouper-settings",
    "href": "content/BaleenWhales/Slides/minkeMethods.html#detection-grouper-settings",
    "title": "Minke Methods",
    "section": "Detection Grouper Settings",
    "text": "Detection Grouper Settings\n\n\n\n\n\nMarkers settings\n\n\n\n\n\n\n\n\nData selection settings\n\n\n\n\n\n\n\n\nAnnotations settings"
  },
  {
    "objectID": "content/BaleenWhales/Slides/minkeMethods.html#create-new-user-form",
    "href": "content/BaleenWhales/Slides/minkeMethods.html#create-new-user-form",
    "title": "Minke Methods",
    "section": "Create New User Form",
    "text": "Create New User Form\n\nIt is important to note that both the “Text” and “User Form” annotation boxes must be selected\n\nTo setup the user form annotation (click on the gear icon)\nCreate new user form\nLabel the form “evType” then click ok"
  },
  {
    "objectID": "content/BaleenWhales/Slides/minkeMethods.html#edit-user-form-add-lookup-table",
    "href": "content/BaleenWhales/Slides/minkeMethods.html#edit-user-form-add-lookup-table",
    "title": "Minke Methods",
    "section": "Edit User Form & Add Lookup Table",
    "text": "Edit User Form & Add Lookup Table\n\n\n\nNext click “edit form”\nAdd a lookup table and fill it out exactly as follows (see figure x.)\n\nTitle: eventType\nPostTitle: eventType\nDbTitle: eventType\nTopic: DGEventType"
  },
  {
    "objectID": "content/BaleenWhales/Slides/minkeMethods.html#edit-lookup-list",
    "href": "content/BaleenWhales/Slides/minkeMethods.html#edit-lookup-list",
    "title": "Minke Methods",
    "section": "Edit Lookup List",
    "text": "Edit Lookup List\n\n\nAdd selection drop down by right clicking on ‘= no selection =’ and selecting ‘Edit list’\n\n\nClick ‘Add item’ and fill in species specific options\n\nB - Boing\nCB - Cutoff Boing\nUB - Unknown Biological Sound\nUA - Unknown Anthropogenic Sound\n\nClick ‘Ok’ to close all of the tabs and return to Pamguard Viewer window"
  },
  {
    "objectID": "content/BaleenWhales/Slides/minkeMethods.html#add-spectrogram-annotation-module",
    "href": "content/BaleenWhales/Slides/minkeMethods.html#add-spectrogram-annotation-module",
    "title": "Minke Methods",
    "section": "Add Spectrogram Annotation Module",
    "text": "Add Spectrogram Annotation Module\n\nGo to File &gt; Add Modules &gt; Utilities &gt; Spectrogram Annotation\nUnder ‘Settings’, go to Spectrogram Annotation settings and click on the gear icon next to ‘User form annotation’\nClick on the ‘User form’ drop down, select ‘UDF_evType’, and click Ok to return to the Pamguard Viewer window"
  },
  {
    "objectID": "content/BaleenWhales/Slides/minkeMethods.html#fix-spectrogram-parameters",
    "href": "content/BaleenWhales/Slides/minkeMethods.html#fix-spectrogram-parameters",
    "title": "Minke Methods",
    "section": "Fix Spectrogram Parameters",
    "text": "Fix Spectrogram Parameters\n\n\n\nRight click on the spectrogram and go to Settings\n\nEnsure both the ‘Detection Grouper’ and ‘Spectrogram Annotation’ boxes are checked and click Ok\n\nGo to File &gt; Save Data and close Pamguard"
  },
  {
    "objectID": "content/BaleenWhales/Slides/minkeMethods.html#detection-validation-1",
    "href": "content/BaleenWhales/Slides/minkeMethods.html#detection-validation-1",
    "title": "Minke Methods",
    "section": "Detection Validation",
    "text": "Detection Validation\nThe data is then manually scanned for minke boings and other sounds of interest using the GPL detections and Pamguard Spectrogram Annotation tool."
  },
  {
    "objectID": "content/BaleenWhales/Slides/minkeMethods.html#spectrogram-annotation",
    "href": "content/BaleenWhales/Slides/minkeMethods.html#spectrogram-annotation",
    "title": "Minke Methods",
    "section": "Spectrogram Annotation",
    "text": "Spectrogram Annotation\nUsing the ‘Generalized Power Law Detector’ Section in the Data Map tab, scroll to detections and center your data there"
  },
  {
    "objectID": "content/BaleenWhales/Slides/minkeMethods.html#spectrogram-annotation-1",
    "href": "content/BaleenWhales/Slides/minkeMethods.html#spectrogram-annotation-1",
    "title": "Minke Methods",
    "section": "Spectrogram Annotation",
    "text": "Spectrogram Annotation\nReturn to the spectrogram view then click and drag to create an annotation box around each boing"
  },
  {
    "objectID": "content/BaleenWhales/Slides/minkeMethods.html#spectrogram-annotation-2",
    "href": "content/BaleenWhales/Slides/minkeMethods.html#spectrogram-annotation-2",
    "title": "Minke Methods",
    "section": "Spectrogram Annotation",
    "text": "Spectrogram Annotation\nA ‘Spectrogram Annotation’ pop up window will appear. In the ‘User form annotation’ section, select the eventType as a ‘Boing’ or other respective option, and press ok"
  },
  {
    "objectID": "content/BaleenWhales/Slides/minkeMethods.html#spectrogram-annotation-3",
    "href": "content/BaleenWhales/Slides/minkeMethods.html#spectrogram-annotation-3",
    "title": "Minke Methods",
    "section": "Spectrogram Annotation",
    "text": "Spectrogram Annotation\nContinue to scan GPL detections and annotate all boings including those missed by the GPL detector, while ignoring false detections"
  },
  {
    "objectID": "content/BaleenWhales/Slides/minkeMethods.html#validation-code",
    "href": "content/BaleenWhales/Slides/minkeMethods.html#validation-code",
    "title": "Minke Methods",
    "section": "20% Validation Code",
    "text": "20% Validation Code\nAfter running the GPL detector and manually scanning all detections, a stratified sub-sampling method was applied to randomly sample 20% of all data for additional validation to look for false negatives.\nThe code below can be used to subsample 20% of the data.\n\n# PAMpal simple example \n# Its on CRAN. Yay!\n# install.packages('PAMpal')\n# Sometimes I fix things and theyre only available on the GitHub version\n# Right now there are some things that run a lot faster on teh GitHub version so I recommend installing that.\n# updated 22-12-6 to include loop for PG event adding w/PAMmisc\nrm(list=ls())\ndevtools::install_github('TaikiSan21/PAMpal')\ndevtools::install_github('TaikiSan21/PAMmisc')\nlibrary(PAMpal)\nlibrary(PAMmisc)\n\n# Start by creating a \"PAMpalSettings\" object. This keeps track of what data you want to process and what processing you want to apply to it.\n\n# Change paths below to your DB and binary folder. Can just be the highest level binary folder for that drift - it will add all files within that folder recursively through subfolders.\n\n# This will also ask you to type in some parameters for calculations in your console. You can just hit ENTER to accept defaults for all of these, they aren't relevant to the GPL calculations only for clicks.\n\npps &lt;- PAMpalSettings(db = 'Path to database',\n                      binaries = 'Path to binaries',\n                      # these parameters are only for the click detector - can ignroe\n                      sr_hz='auto',\n                      filterfrom_khz=0,\n                      filterto_khz=NULL,\n                      winLen_sec=.0025)\n\n# Now tell it to process your data. Id is optional and serves no function, but can be useful to tell data apart at a later point in time. Here mode = 'recording' tells it how to organize your data. Most of the time we are working with data that have been marked manually into events, so PAMpal wants to organize things into events. mode='db' uses the events in the database, and only processes the detectoins you've marked out. In this case we just want to process everything, which is what mode='recording' does. It will group them into events by recording file. \n\n# This might take some time to read in events after processing in order to get the time \n#data &lt;- processPgDetections(pps, mode='db', id='Minke_CCES_019') \n\ndata &lt;- processPgDetections(pps, mode='recording', id='Species_Project_Drift#')\n\n# And here's how you can get the detections information out of \"data\" as a dataframe. Time column is \"UTC\", other columns are stuff it measured. \ngplDf &lt;- getGPLData(data)\n\n# Now we can add the wav files to this data. You might get a warning about \"startSample\", its safe to ignore that.\ndata &lt;- addRecordings(data, \n                      folder='Path to wav files')\n\n# that data is stored here as a dataframe. Has \"start\" & \"end\" as POSIXct and the fulle path to the file as \"file\"\nwavDf &lt;- files(data)$recordings\n\n# add number of detections to this\nnDets &lt;- sapply(events(data), nDetections)\nnDets &lt;- data.frame(join=names(nDets), nDets=nDets)\nwavDf$join &lt;- basename(wavDf$file)\nwavDf &lt;- left_join(wavDf, nDets)\nwavDf$join &lt;- NULL\nwavDf$nDets[is.na(wavDf$nDets)] &lt;- 0\n\nnfiles =round(nrow(wavDf)*.2)\nrandStart =sample(1:5,1)\n\nwavDf=wavDf[round(seq(randStart, nrow(wavDf), length.out = nfiles)),]\n\n# If we care about assigning some kind of initial label to these detections. Otherwise ignore. \ndata &lt;- setSpecies(data, method='manual', value='InitialGPL')\n\n# Add events from wavDf loop\nfor(e in 1:nrow(wavDf)) {\n  thisEv &lt;- data[[basename(wavDf$file[e])]]\n  # this will get all detector types, if just one type is wanted can be simplified to ex. uids &lt;- unique(getGPLData(thisEv)$UID)\n  uids &lt;- unique(unlist(lapply(getDetectorData(thisEv), function(x) {\n    if(is.null(x)) return(NULL)\n    x$UID\n  })))\n  \n  addPgEvent(db = files(thisEv)$db,\n             binary = files(thisEv)$binaries,\n             eventType = species(thisEv)$id,\n             UIDs = uids,\n             type = 'dg',\n             start = wavDf$start[e],\n             end = wavDf$end[e],\n             comment = paste0('Added by PAMpal, event ID: ', id(thisEv)))\n}"
  },
  {
    "objectID": "content/BaleenWhales/Slides/minkeMethods.html#validation-steps",
    "href": "content/BaleenWhales/Slides/minkeMethods.html#validation-steps",
    "title": "Minke Methods",
    "section": "20% Validation Steps",
    "text": "20% Validation Steps\n\nOnce you have followed the code above to subsample your data, make a copy of the database in a ‘Data Validated’ folder and reopen the database in Pamguard Viewer\nGo to File &gt; Add Modules &gt; Displays &gt; User Display\n\n\n\nName the new user display ‘Subsample’\nClick on the new subsample tab and go to User Display &gt; New Detection Grouper data display\n\n\n\nYour subsampled data should then be listed with associate marker colors\n\n\n\nValidate each subsampled wav file by scrolling in the spectrogram to the file and scanning for boings\n\n\n\n\nBack to baleen whale methods overview"
  },
  {
    "objectID": "content/BaleenWhales/Slides/20HzFinMethods.html#detecting-20hz-fin-pulses-in-pamguard",
    "href": "content/BaleenWhales/Slides/20HzFinMethods.html#detecting-20hz-fin-pulses-in-pamguard",
    "title": "Semi-Automated Approach to Detecting 20Hz Fin Whale Pulses",
    "section": "Detecting 20Hz fin pulses in PAMGuard",
    "text": "Detecting 20Hz fin pulses in PAMGuard\n\nCurrently we are using PAMGuard version 2.02.09.\nWe used the click detector to identify fin pulses and classify them at 20Hz “clicks”"
  },
  {
    "objectID": "content/BaleenWhales/Slides/20HzFinMethods.html#step-1-open-pamguard",
    "href": "content/BaleenWhales/Slides/20HzFinMethods.html#step-1-open-pamguard",
    "title": "Semi-Automated Approach to Detecting 20Hz Fin Whale Pulses",
    "section": "Step 1: Open PAMGuard",
    "text": "Step 1: Open PAMGuard\n\n\n\nOpen PAMgaurd and navigate to the settings file that has “FinClick” in the name"
  },
  {
    "objectID": "content/BaleenWhales/Slides/20HzFinMethods.html#step-2-change-output-settings-for-your-drift",
    "href": "content/BaleenWhales/Slides/20HzFinMethods.html#step-2-change-output-settings-for-your-drift",
    "title": "Semi-Automated Approach to Detecting 20Hz Fin Whale Pulses",
    "section": "Step 2: Change output settings for your Drift",
    "text": "Step 2: Change output settings for your Drift\n\nLoad a new database with the following naming structure\n\nADRIFT_###_PG_2_02_09_FinClick.sqlite3\n\nSetup a new Binary files folder\n\nWe want each Drift to have it’s own Binary files"
  },
  {
    "objectID": "content/BaleenWhales/Slides/20HzFinMethods.html#step-3-update-the-array-file",
    "href": "content/BaleenWhales/Slides/20HzFinMethods.html#step-3-update-the-array-file",
    "title": "Semi-Automated Approach to Detecting 20Hz Fin Whale Pulses",
    "section": "Step 3: Update the Array File",
    "text": "Step 3: Update the Array File\n\n\n\nOpen Hydrophone array settings\n\nModify settings to match deployment details for the specific array used for your drift"
  },
  {
    "objectID": "content/BaleenWhales/Slides/20HzFinMethods.html#step-4-decimator-settings",
    "href": "content/BaleenWhales/Slides/20HzFinMethods.html#step-4-decimator-settings",
    "title": "Semi-Automated Approach to Detecting 20Hz Fin Whale Pulses",
    "section": "Step 4: Decimator Settings",
    "text": "Step 4: Decimator Settings\n\nCheck to see that your decimator settings match the settings below"
  },
  {
    "objectID": "content/BaleenWhales/Slides/20HzFinMethods.html#step-5-sound-acquisition",
    "href": "content/BaleenWhales/Slides/20HzFinMethods.html#step-5-sound-acquisition",
    "title": "Semi-Automated Approach to Detecting 20Hz Fin Whale Pulses",
    "section": "Step 5: Sound Acquisition",
    "text": "Step 5: Sound Acquisition\n\n\n\nNavigate to your sound files\n\nWe used 12kHz files, which were previously decimated in Triton Software\n\nDue to an offset at the beginning of the SoundTrap wav files, we need to make sure to skip the initial 3 seconds of the recording\nYour settings should look like the following below"
  },
  {
    "objectID": "content/BaleenWhales/Slides/20HzFinMethods.html#step-6-check-the-digital-pre-and-trigger-filter-settings",
    "href": "content/BaleenWhales/Slides/20HzFinMethods.html#step-6-check-the-digital-pre-and-trigger-filter-settings",
    "title": "Semi-Automated Approach to Detecting 20Hz Fin Whale Pulses",
    "section": "Step 6: Check the Digital Pre and Trigger filter Settings",
    "text": "Step 6: Check the Digital Pre and Trigger filter Settings\n\n\n\n\n\nDigital Pre Filter Settings\n\n\n\n\n\n\nDigital Trigger Filter Settings"
  },
  {
    "objectID": "content/BaleenWhales/Slides/20HzFinMethods.html#step-7-check-the-click-detector-settings",
    "href": "content/BaleenWhales/Slides/20HzFinMethods.html#step-7-check-the-click-detector-settings",
    "title": "Semi-Automated Approach to Detecting 20Hz Fin Whale Pulses",
    "section": "Step 7: Check the Click Detector Settings",
    "text": "Step 7: Check the Click Detector Settings\n-The settings for the first three tabs should be as follows. The rest of the tabs can be left to their default\n\n\n\n\n\nClick Detector Source\n\n\n\n\n\n\nClick Detector Trigger\n\n\n\n\n\n\nClick Detector Click Length"
  },
  {
    "objectID": "content/BaleenWhales/Slides/20HzFinMethods.html#step-8-process-each-drift",
    "href": "content/BaleenWhales/Slides/20HzFinMethods.html#step-8-process-each-drift",
    "title": "Semi-Automated Approach to Detecting 20Hz Fin Whale Pulses",
    "section": "Step 8: Process each Drift",
    "text": "Step 8: Process each Drift\n\n\n\nClick the play button and let your wav files run through PAMGuard\n\n20Hz Fin Pulses should have Wigner Plots that are down swept\nPeak frequency will be close to 20-25Hz with some variability"
  },
  {
    "objectID": "content/BaleenWhales/Slides/20HzFinMethods.html#step-9-create-events-in-pampal",
    "href": "content/BaleenWhales/Slides/20HzFinMethods.html#step-9-create-events-in-pampal",
    "title": "Semi-Automated Approach to Detecting 20Hz Fin Whale Pulses",
    "section": "Step 9: Create Events in PAMpal",
    "text": "Step 9: Create Events in PAMpal\n-The code below can be used to subsample 20% of the data. We used a stratified sub-sampling method that looks at 1 out of every 5 wav files. Before running this code, create a copy of the original database and place it in a new folder so that we don’t write over the originals.\n\n# PAMpal simple example \n# install.packages('PAMpal')\n# updated 22-12-6 to include loop for PG event adding w/PAMmisc\n# UPDATE 2023-09-06:\n#   Changed first processing from mode='recording' because there were\n#   DST-related bugs on some drifts. Lines 45-48 updated.\n\nrm(list=ls())\ndevtools::install_github('TaikiSan21/PAMpal')\ndevtools::install_github('TaikiSan21/PAMmisc')\nlibrary(PAMpal)\nlibrary(PAMmisc)\n\n# Start by creating a \"PAMpalSettings\" object. This keeps track of what data\n# you want to process and what processing you want to apply to it.\n\n# Change paths below to your DB and binary folder. Can just be the \n# highest level binary folder for that drift - it will add all files\n# within that folder recursively through subfolders.\n\n# This will also ask you to type in some parameters for calculations\n# in your console. You can just hit ENTER to accept defaults for all\n# of these, they aren't relevant to the GPL calculations only for clicks.\n\npps &lt;- PAMpalSettings(db = 'H:/DATA/PAMGUARD_FIN_CLICK/AddFinEvent/ADRIFT_053_PG_2_02_02_FinClick.sqlite3',\n                      binaries = 'H:/DATA/PAMGUARD_FIN_CLICK/FinClickDetector_Run/Binaries/ADRIFT_053',\n                      # these parameters are only for the click detector - can ignore\n                      sr_hz=200,\n                      filterfrom_khz=0,\n                      filterto_khz=NULL,\n                      winLen_sec=1)\n\n# Now tell it to process your data. Id is optional and serves no function,\n# but can be useful to tell data apart at a later point in time. Here\n# mode = 'recording' tells it how to organize your data. Most of the time\n# we are working with data that have been marked manually into events, \n# so PAMpal wants to organize things into events. mode='db' uses the events\n# in the database, and only processes the detectoins you've marked out.\n# In this case we just want to process everything, which is what \n# mode='recording' does. It will group them into events by recording file. \n\n# This might take some time\n\n# to read in events after processing in order to get the tim\n#data &lt;- processPgDetections(pps, mode='db', id='Humpback007') \nwavFolder &lt;- 'H:/RECORDINGS/12kHz/ADRIFT_053_CENSOR_12kHz'\nwavGroups &lt;- PAMpal:::mapWavFolder(wavFolder)\nwavGroups$id &lt;- basename(wavGroups$file)\ndata &lt;- processPgDetections(pps, mode='time', grouping=wavGroups, id='Fin_ADRIFT_53')\n# data &lt;- processPgDetections(pps, mode='recording', id='Fin_ADRIFT_53')\n\n# And here's how you can get the detections information out of \"data\"\n# as a dataframe. Time column is \"UTC\", other columns are stuff it\n# measured. \nclickDf &lt;- getClickData(data)\n\n# Now we can add the wav files to this data. You might get a warning about\n# \"startSample\", its safe to ignore that.\ndata &lt;- addRecordings(data, folder=wavFolder)\n\n# that data is stored here as a dataframe. Has \"start\" & \"end\" as POSIXct and\n# the fulle path to the file as \"file\"\nwavDf &lt;- files(data)$recordings\n# add number of detections to this\nnDets &lt;- sapply(events(data), nDetections)\nnDets &lt;- data.frame(join=names(nDets), nDets=nDets)\nwavDf$join &lt;- basename(wavDf$file)\nwavDf &lt;- left_join(wavDf, nDets)\nwavDf$join &lt;- NULL\nwavDf$nDets[is.na(wavDf$nDets)] &lt;- 0\n\nnfiles =round(nrow(wavDf)*.2)\nrandStart =sample(1:5,1)\n\nwavDf=wavDf[round(seq(randStart, nrow(wavDf), length.out = nfiles)),]\n\n\n\n\n# If we care about assigning some kind of initial label to these\n# detections. Otherwise ignore. \ndata &lt;- setSpecies(data, method='manual', value='fin_click')\n\n# Add events from wavDf loop\nfor(e in 1:nrow(wavDf)) {\n  thisEv &lt;- data[[basename(wavDf$file[e])]]\n  # this will get all detector types, if just one type is wanted can\n  # be simplified to ex. uids &lt;- unique(getGPLData(thisEv)$UID)\n  uids &lt;- unique(unlist(lapply(getDetectorData(thisEv), function(x) {\n    if(is.null(x)) return(NULL)\n    x$UID\n  })))\n  \n  addPgEvent(db = files(thisEv)$db,\n             binary = files(thisEv)$binaries,\n             eventType = species(thisEv)$id,\n             UIDs = uids,\n             type = 'click',\n             start = wavDf$start[e],\n             end = wavDf$end[e],\n             comment = paste0('Added by PAMpal, event ID: ', id(thisEv)))\n}"
  },
  {
    "objectID": "content/BaleenWhales/Slides/20HzFinMethods.html#step-10-open-the-database-in-viewer-mode",
    "href": "content/BaleenWhales/Slides/20HzFinMethods.html#step-10-open-the-database-in-viewer-mode",
    "title": "Semi-Automated Approach to Detecting 20Hz Fin Whale Pulses",
    "section": "Step 10: Open the Database in Viewer Mode",
    "text": "Step 10: Open the Database in Viewer Mode\n\n\n\nOpen the database that you have added events to with PAMGuard Viewer Mode\n\nUse the original binary files\n\nCheck to see that your events were added correctly under Click Detection–&gt;Show events\n\n\n\n\n\nEvents added through PAMpal"
  },
  {
    "objectID": "content/BaleenWhales/Slides/20HzFinMethods.html#step-11-add-spectrogram-annotation-moduel",
    "href": "content/BaleenWhales/Slides/20HzFinMethods.html#step-11-add-spectrogram-annotation-moduel",
    "title": "Semi-Automated Approach to Detecting 20Hz Fin Whale Pulses",
    "section": "Step 11: Add Spectrogram Annotation Moduel",
    "text": "Step 11: Add Spectrogram Annotation Moduel\n\n\n\nOpen the database that you have added events to with PAMGuard Viewer Mode\n\nUse the original binary files\n\nAdd the “Spectrogram Annotation Moduel”\nOnce added you should see “Spectrogram Annotation Settings” under the settings menu"
  },
  {
    "objectID": "content/BaleenWhales/Slides/20HzFinMethods.html#step-12-add-lookup-table",
    "href": "content/BaleenWhales/Slides/20HzFinMethods.html#step-12-add-lookup-table",
    "title": "Semi-Automated Approach to Detecting 20Hz Fin Whale Pulses",
    "section": "Step 12: Add LOOKUP Table",
    "text": "Step 12: Add LOOKUP Table\n\n\n\nClick on the gear icon for the “User Form Annotation” check box\nClick on “Create New”\n\nA new dialog will pop up and under the left side you will Add a LOOKUP table\nFill in the metadata for the table as follows"
  },
  {
    "objectID": "content/BaleenWhales/Slides/20HzFinMethods.html#step-13-add-drop-down-list-for-lookup-table",
    "href": "content/BaleenWhales/Slides/20HzFinMethods.html#step-13-add-drop-down-list-for-lookup-table",
    "title": "Semi-Automated Approach to Detecting 20Hz Fin Whale Pulses",
    "section": "Step 13: Add drop down list for LOOKUP table",
    "text": "Step 13: Add drop down list for LOOKUP table\n\n\n\nRight click on the drop down menu to the right of the Topic section\nClick on edit list\n\nAdd the following 4 options as seen in the image to the right\nClick ok on all of the promts\nIn order for your settings to work you will need to save and restart PAMGaurd"
  },
  {
    "objectID": "content/BaleenWhales/Slides/20HzFinMethods.html#step-14-make-a-copy-of-the-events-database",
    "href": "content/BaleenWhales/Slides/20HzFinMethods.html#step-14-make-a-copy-of-the-events-database",
    "title": "Semi-Automated Approach to Detecting 20Hz Fin Whale Pulses",
    "section": "Step 14: Make a Copy of the Events Database",
    "text": "Step 14: Make a Copy of the Events Database\n\nWe will be comparing the Original Events Database with the Validated Database to pull out metrics such as false positives, false negatives, true positives, true negative and precision and recall\n\nThis is why we need to validate a copy of the events database and keep one untouched"
  },
  {
    "objectID": "content/BaleenWhales/Slides/20HzFinMethods.html#step-15-start-validating-events",
    "href": "content/BaleenWhales/Slides/20HzFinMethods.html#step-15-start-validating-events",
    "title": "Semi-Automated Approach to Detecting 20Hz Fin Whale Pulses",
    "section": "Step 15: Start Validating Events",
    "text": "Step 15: Start Validating Events\n\nUse the Click Detector Event List to Navigate to each event\n\nUse the click detector to add or remove clicks to an event\n\nUse the Wigner and the click spectrum to determine if the click is a 20Hz fin pulse\nLook at the spectrogram and see if the click looks like a 20Hz fin pulse\n\n\n\n\n\n\n\n\nFin pulses in the click detector. Click spectrum shows a peak around 20Hz. The wigner shows a slight down sweep.\n\n\n\n\n\n\n20Hz Fin Pulses (purple triangles represent where the click detector has picked up a pulse)"
  },
  {
    "objectID": "content/BaleenWhales/Slides/20HzFinMethods.html#step-16-annotate-missed-fin-pulses-on-the-spectrogram-display",
    "href": "content/BaleenWhales/Slides/20HzFinMethods.html#step-16-annotate-missed-fin-pulses-on-the-spectrogram-display",
    "title": "Semi-Automated Approach to Detecting 20Hz Fin Whale Pulses",
    "section": "Step 16: Annotate Missed Fin Pulses on the Spectrogram Display",
    "text": "Step 16: Annotate Missed Fin Pulses on the Spectrogram Display\n\n\n\nScroll through each event using the spectrogram display\n\nAnnotate any 20Hz pulse that was missed by the click detector\nDraw a box around the click and use the drop down menu to select the sound you’re boxing\n\n\n\n\n\n\nSpectrogram Annotation\n\n\n\n\n\n\n\nBack to Methods"
  },
  {
    "objectID": "content/BaleenWhales/Gray_and_HumpbackWhales-Detection.html",
    "href": "content/BaleenWhales/Gray_and_HumpbackWhales-Detection.html",
    "title": "Gray & Humpback Whales - Detection",
    "section": "",
    "text": "*To view the Pamguard settings files used for each drift please click here.\n\n\nDepending on the drift that was process the array settings in Pamguard were updated to reflect the spacing between hydrophones and the hydrophone sensitivity. For our purposes we only used CH0 in Pamguard to run the detector.\n\n\n\nFigure X. Array settings in Pamguard\n\n\n\n\n\n\nFor humpback and gray whales we decimated files to 10kHz (Figure X.) and used a Butterworth Low Pass Filter of 5kHz (Figure x).\n\n\n\nFigure x. Settings used in the decimator module in Pamguard to run the humpback and gray whale GPL detector.\n\n\n\n\n\nFigure x. Low Pass Filter for Humback and Gray whale GPL detector\n\n\n\n\n\n\n\nWe started with basic GPL settings from Tyler Helble’s PARM files and modified them to fit our data. For the humpback and gray whales we tested modified settings on clips that contained either humpback or gray whales until we were happy with the detectors performance.\n\n\n\n\nFigure X. GPL FFT Settings for humpback and gray whales\n\n\n\n\n\nFigure x. GPL detections settings for humpback and gray whales\n\n\n\n\n\nFigure x. GPL contour settings for humpback and gray whales\n\n\n\nWe then processed an entire drift’s recordings and looked at the detector’s performance in Pamguard Viewer Mode by spot checking that humpback and gray whale calls were being picked up by the detector. Once we were satisfied that the detector was doing it’s job, we processed the rest of the drifts.\n\nFor this detector our aim was to over-detect and then sort out the differences between the humpback and gray detections using a classifier.\n\n\n\n\n\n\nIn order for PAMpal to interact with the GPL detections we added in the Detection Grouper Module. This allows PAMpal to create events and push them back in the SQLite database in PAMGuard.\n\n\n\nFigure x. Detection Grouper Mark Display Settings\n\n\n\n\n\nFigure X. Detection Grouper Data Selection Settings\n\n\n\n\n\nFigure x. Detection Grouper Annotation Settings\n\n\nIt is important to note that both the “Text” and “User Form” annotation boxes must be selected here.\n\nTo setup the user form annotation (click on the gear icon)\nCreate new user form\nLabel the form “evType” then click ok (see figure X)\n\n\n\nFigure x. Adding in a user form for the Detection Grouper in Pamguard\n\n\nNext click “edit form”\nAdd a lookup table and fill it out exactly as follows (see figure x.)\n\nTitle: eventType\nPostTitle: eventType\nDbTitle: eventType\nTopic: DGEventType\n\n\n\nFigure x. Editing the user form for the detection grouper to work with the GPL detections\n\n\n\n\n\n\n\n\n\nAll detections were saved to the binary files and all other data were saved to a SQLite database\n\n\n\nFigure x. Storage Options Settings for PAMGuard"
  },
  {
    "objectID": "content/BaleenWhales/Gray_and_HumpbackWhales-Detection.html#pamguard",
    "href": "content/BaleenWhales/Gray_and_HumpbackWhales-Detection.html#pamguard",
    "title": "Gray & Humpback Whales - Detection",
    "section": "",
    "text": "*To view the Pamguard settings files used for each drift please click here.\n\n\nDepending on the drift that was process the array settings in Pamguard were updated to reflect the spacing between hydrophones and the hydrophone sensitivity. For our purposes we only used CH0 in Pamguard to run the detector.\n\n\n\nFigure X. Array settings in Pamguard\n\n\n\n\n\n\nFor humpback and gray whales we decimated files to 10kHz (Figure X.) and used a Butterworth Low Pass Filter of 5kHz (Figure x).\n\n\n\nFigure x. Settings used in the decimator module in Pamguard to run the humpback and gray whale GPL detector.\n\n\n\n\n\nFigure x. Low Pass Filter for Humback and Gray whale GPL detector\n\n\n\n\n\n\n\nWe started with basic GPL settings from Tyler Helble’s PARM files and modified them to fit our data. For the humpback and gray whales we tested modified settings on clips that contained either humpback or gray whales until we were happy with the detectors performance.\n\n\n\n\nFigure X. GPL FFT Settings for humpback and gray whales\n\n\n\n\n\nFigure x. GPL detections settings for humpback and gray whales\n\n\n\n\n\nFigure x. GPL contour settings for humpback and gray whales\n\n\n\nWe then processed an entire drift’s recordings and looked at the detector’s performance in Pamguard Viewer Mode by spot checking that humpback and gray whale calls were being picked up by the detector. Once we were satisfied that the detector was doing it’s job, we processed the rest of the drifts.\n\nFor this detector our aim was to over-detect and then sort out the differences between the humpback and gray detections using a classifier.\n\n\n\n\n\n\nIn order for PAMpal to interact with the GPL detections we added in the Detection Grouper Module. This allows PAMpal to create events and push them back in the SQLite database in PAMGuard.\n\n\n\nFigure x. Detection Grouper Mark Display Settings\n\n\n\n\n\nFigure X. Detection Grouper Data Selection Settings\n\n\n\n\n\nFigure x. Detection Grouper Annotation Settings\n\n\nIt is important to note that both the “Text” and “User Form” annotation boxes must be selected here.\n\nTo setup the user form annotation (click on the gear icon)\nCreate new user form\nLabel the form “evType” then click ok (see figure X)\n\n\n\nFigure x. Adding in a user form for the Detection Grouper in Pamguard\n\n\nNext click “edit form”\nAdd a lookup table and fill it out exactly as follows (see figure x.)\n\nTitle: eventType\nPostTitle: eventType\nDbTitle: eventType\nTopic: DGEventType\n\n\n\nFigure x. Editing the user form for the detection grouper to work with the GPL detections\n\n\n\n\n\n\n\n\n\nAll detections were saved to the binary files and all other data were saved to a SQLite database\n\n\n\nFigure x. Storage Options Settings for PAMGuard"
  },
  {
    "objectID": "content/BaleenWhales/Gray_and_HumpbackWhales-Detection.html#pampal",
    "href": "content/BaleenWhales/Gray_and_HumpbackWhales-Detection.html#pampal",
    "title": "Gray & Humpback Whales - Detection",
    "section": "PAMpal",
    "text": "PAMpal\n\nThe data were then imported into PAMpal and events were created and put back into the PAMGuard database. Events were defined as 6 minute periods of continuous recordings for ADRIFT and 2 minutes for the CCES 2018 data set (limited to duty cycle 2 on 18 off) . *Add in PASCAL when we get to it."
  },
  {
    "objectID": "content/BaleenWhales/Gray_and_HumpbackWhales-Detection.html#stratified-sub-sampling",
    "href": "content/BaleenWhales/Gray_and_HumpbackWhales-Detection.html#stratified-sub-sampling",
    "title": "Gray & Humpback Whales - Detection",
    "section": "Stratified Sub-sampling",
    "text": "Stratified Sub-sampling\n\nDue to the nature of this large data set we decided to use a stratified sub-sampling method to randomly sample 20% of all events for validation.\n*Add in Kaitlin’s code"
  },
  {
    "objectID": "content/BaleenWhales/Gray_and_HumpbackWhales-Detection.html#validation",
    "href": "content/BaleenWhales/Gray_and_HumpbackWhales-Detection.html#validation",
    "title": "Gray & Humpback Whales - Detection",
    "section": "Validation",
    "text": "Validation\n\n*Kaitlin to add in methods here"
  },
  {
    "objectID": "content/BaleenWhales/Overview.html",
    "href": "content/BaleenWhales/Overview.html",
    "title": "Overview",
    "section": "",
    "text": "Baleen whale vocalizations are noted by their long duration, low frequency calls. While we wanted to come up with one approach to detect and classify all baleen whale species in the California Current, existing open source software did not provide the best platform to do so. Here we summarize multiple methods on how we tackled the problem of detecting and classifying baleen whales in the the ADRIFT recordings.\n\n\n\nRecordings from ADRIFT, CCES, and PASCAL were originally sampled between 192kHz and 576kHz. In order to examine these recordings for baleen whales they were decimated in Triton software to 12kHz and 500Hz respectively using channel one of the raw recordings.\nFrom those decimated recordings, Triton software was used to create long-term spectral averages (LTSAs) for each Drift at both 12kHz and 500Hz respectively.\n\nLTSAs were reviewed by an experienced analyst as an initial QAQC of our recordings in that frequency range. If it was determined that the recordings were unusable in a specific frequency then that was noted in the Deployment Details.\n\n\n\n\n\n\n\n\nPresence of blue whales within the recordings were based off of A, B, and D call types.\nTriton software was used for the following:\n\nLong-term spectral averages (LTSAs) were calculated with a 1 Hz, 5 second resolution using 500Hz decimated recordings\nA trained analyst scanned the LTSAs one hour at a time to look for A, B and D calls. If a call was discovered within that hour chunk, the analyst would note the start time of each call type and a comment regarding the SNR and quality of the call.\nThese annotations were saved in a .CSV for each deployment. CSVs were then combined and plots for hourly presence were created.\n\nClick here for more detail of these methods.\n\n\n\n\n\n\n\n\n\n\n\nPAMGuard software was used to automatically detect fin whale 20Hz pulses in the ADRIFT data set.\n\nA click classifier was created to classify 20Hz fin whale pulses as “fin clicks”\n\nPamGuard settings can be found here\n\nRecordings from each Drift was run through the click detector\nClick information were saved to binary files\n\n\n\n\n\n\nPAMpal was used to create fin whale events in each database\n\nEvents were defined as every wav file\nWav file lengths and duty cycles varied depending on deployment but all information related to deployment details can be found here.\n\n\n\n\n\n\nA random forest model was created using validated data from 14 drifts, deployed in 3 different locations between June of 2021-July 2023\n\n\n\n\n\nWe used the model to predict if fin whales were present on an hourly basis\nThe model had one of three results: Accept, Review, Dropped\nBoth Accepted and Review detections were reviewed for accuracy\n\nMore detail of these methods can be found here\n\n\n\n\nDownsampled audio data (12 kHz) were visualized as spectrograms and manually browsed for the presence of humpback and gray whale calls using Raven Pro v. 1.6.4. Spectrogram settings included a 4096pt fft length with a Han window 90% overlap resulting in a 341 ms time and 4.21hz frequency resolution. All drifts were manually scanned for humpback and gray whale calls and hourly presence was indicated, regardless of duty-cycling regime.\nAll annotation files were stored as Raven Selection tables containing columns for the start and end time, relative to the beginning of the drift audio files, date and time at the start of the annotation in yyyy/mm/dd HH:MM:SS, low and high frequency, Species, Hour of the day-for hourly presence analysis, and additional Notes column.\n\n\nHumpback annotations were labeled as either humpback song, (HmpSng), humpback social (HmpSoc), or undetermined humpback calls (Hmp).\n\nThe humpback song category contained sections of calls where at least two notes of a theme were clearly visible and produced twice\n\nThis qualification was relaxed when song segments were clearly visible in the preceding hour and were reduced in SNR or masked by impulsive sounds (i.e. increasing distance between the animal and drifter)\n\nThe humpback social category included whops and grunt sequences, that are stereotyped and could be clearly discriminated (Dundop et al. 2008)\nThe undetermined humpback category was a catch all for calls that did not clearly fit into either song or social category\n\nThis was often used when calls were low SNR or diverse in visual and aural appearance\n\n\nDuring the annotation process at least one call of each class was noted for each hour where present. However, multiple annotations were per hour were occasionally made where subjectively higher SNR signals were found after the initial annotation. In other words, some effort was made to select the highest SNR calls\n\n\n\nThe presence of gray whales was also indicated but classes were not specified. However, it should be noted that there is considerable overlap in the repertoires of humpback whales and gray whales and as such, care should be taken when inferring gray whale presence from audio with concurrent humpback whale presence.\n\n\n\nCross validation of a portion of the calls was completed with Dr. Alison Stimpert. In this process, a selection of uncertain annotations were collaboratively reviewed to ensure consistency between expert analysts.\n\n\n\n\n\nPAMGuard software was used to run a Generalized Power Law (GPL) detector to identify Minke whale boings (see image below)\nAll detections were manually scanned and all boings were annotated using PAMGuard Viewer Mode’s Spectrogram Annotation Tool\nFollowing manual scanning, an additional 20% of the total data was subsampled to look for false negative boings\nThe annotations were then summarized into hourly presence/absence tables.\n\n\n\n\nFigure X. Spectrogram of Minke whale boings being detected by GPL detector\n\n\nClick here for more detailed methods",
    "crumbs": [
      "Baleen Whales",
      "Overview"
    ]
  },
  {
    "objectID": "content/BaleenWhales/Overview.html#data-prep",
    "href": "content/BaleenWhales/Overview.html#data-prep",
    "title": "Overview",
    "section": "",
    "text": "Recordings from ADRIFT, CCES, and PASCAL were originally sampled between 192kHz and 576kHz. In order to examine these recordings for baleen whales they were decimated in Triton software to 12kHz and 500Hz respectively using channel one of the raw recordings.\nFrom those decimated recordings, Triton software was used to create long-term spectral averages (LTSAs) for each Drift at both 12kHz and 500Hz respectively.\n\nLTSAs were reviewed by an experienced analyst as an initial QAQC of our recordings in that frequency range. If it was determined that the recordings were unusable in a specific frequency then that was noted in the Deployment Details.",
    "crumbs": [
      "Baleen Whales",
      "Overview"
    ]
  },
  {
    "objectID": "content/BaleenWhales/Overview.html#blue-whales",
    "href": "content/BaleenWhales/Overview.html#blue-whales",
    "title": "Overview",
    "section": "",
    "text": "Presence of blue whales within the recordings were based off of A, B, and D call types.\nTriton software was used for the following:\n\nLong-term spectral averages (LTSAs) were calculated with a 1 Hz, 5 second resolution using 500Hz decimated recordings\nA trained analyst scanned the LTSAs one hour at a time to look for A, B and D calls. If a call was discovered within that hour chunk, the analyst would note the start time of each call type and a comment regarding the SNR and quality of the call.\nThese annotations were saved in a .CSV for each deployment. CSVs were then combined and plots for hourly presence were created.\n\nClick here for more detail of these methods.",
    "crumbs": [
      "Baleen Whales",
      "Overview"
    ]
  },
  {
    "objectID": "content/BaleenWhales/Overview.html#fin-20-hz-adrift",
    "href": "content/BaleenWhales/Overview.html#fin-20-hz-adrift",
    "title": "Overview",
    "section": "",
    "text": "PAMGuard software was used to automatically detect fin whale 20Hz pulses in the ADRIFT data set.\n\nA click classifier was created to classify 20Hz fin whale pulses as “fin clicks”\n\nPamGuard settings can be found here\n\nRecordings from each Drift was run through the click detector\nClick information were saved to binary files\n\n\n\n\n\n\nPAMpal was used to create fin whale events in each database\n\nEvents were defined as every wav file\nWav file lengths and duty cycles varied depending on deployment but all information related to deployment details can be found here.\n\n\n\n\n\n\nA random forest model was created using validated data from 14 drifts, deployed in 3 different locations between June of 2021-July 2023\n\n\n\n\n\nWe used the model to predict if fin whales were present on an hourly basis\nThe model had one of three results: Accept, Review, Dropped\nBoth Accepted and Review detections were reviewed for accuracy\n\nMore detail of these methods can be found here",
    "crumbs": [
      "Baleen Whales",
      "Overview"
    ]
  },
  {
    "objectID": "content/BaleenWhales/Overview.html#gray-and-humpack",
    "href": "content/BaleenWhales/Overview.html#gray-and-humpack",
    "title": "Overview",
    "section": "",
    "text": "Downsampled audio data (12 kHz) were visualized as spectrograms and manually browsed for the presence of humpback and gray whale calls using Raven Pro v. 1.6.4. Spectrogram settings included a 4096pt fft length with a Han window 90% overlap resulting in a 341 ms time and 4.21hz frequency resolution. All drifts were manually scanned for humpback and gray whale calls and hourly presence was indicated, regardless of duty-cycling regime.\nAll annotation files were stored as Raven Selection tables containing columns for the start and end time, relative to the beginning of the drift audio files, date and time at the start of the annotation in yyyy/mm/dd HH:MM:SS, low and high frequency, Species, Hour of the day-for hourly presence analysis, and additional Notes column.\n\n\nHumpback annotations were labeled as either humpback song, (HmpSng), humpback social (HmpSoc), or undetermined humpback calls (Hmp).\n\nThe humpback song category contained sections of calls where at least two notes of a theme were clearly visible and produced twice\n\nThis qualification was relaxed when song segments were clearly visible in the preceding hour and were reduced in SNR or masked by impulsive sounds (i.e. increasing distance between the animal and drifter)\n\nThe humpback social category included whops and grunt sequences, that are stereotyped and could be clearly discriminated (Dundop et al. 2008)\nThe undetermined humpback category was a catch all for calls that did not clearly fit into either song or social category\n\nThis was often used when calls were low SNR or diverse in visual and aural appearance\n\n\nDuring the annotation process at least one call of each class was noted for each hour where present. However, multiple annotations were per hour were occasionally made where subjectively higher SNR signals were found after the initial annotation. In other words, some effort was made to select the highest SNR calls\n\n\n\nThe presence of gray whales was also indicated but classes were not specified. However, it should be noted that there is considerable overlap in the repertoires of humpback whales and gray whales and as such, care should be taken when inferring gray whale presence from audio with concurrent humpback whale presence.\n\n\n\nCross validation of a portion of the calls was completed with Dr. Alison Stimpert. In this process, a selection of uncertain annotations were collaboratively reviewed to ensure consistency between expert analysts.",
    "crumbs": [
      "Baleen Whales",
      "Overview"
    ]
  },
  {
    "objectID": "content/BaleenWhales/Overview.html#minke",
    "href": "content/BaleenWhales/Overview.html#minke",
    "title": "Overview",
    "section": "",
    "text": "PAMGuard software was used to run a Generalized Power Law (GPL) detector to identify Minke whale boings (see image below)\nAll detections were manually scanned and all boings were annotated using PAMGuard Viewer Mode’s Spectrogram Annotation Tool\nFollowing manual scanning, an additional 20% of the total data was subsampled to look for false negative boings\nThe annotations were then summarized into hourly presence/absence tables.\n\n\n\n\nFigure X. Spectrogram of Minke whale boings being detected by GPL detector\n\n\nClick here for more detailed methods",
    "crumbs": [
      "Baleen Whales",
      "Overview"
    ]
  },
  {
    "objectID": "content/BaleenWhales/Dectections.html",
    "href": "content/BaleenWhales/Dectections.html",
    "title": "Detection",
    "section": "",
    "text": "*To view the Pamguard settings files used for each drift please click here.\n\n\nDepending on the drift that was processed, the array settings in Pamguard were updated to reflect the spacing between hydrophones and the hydrophone sensitivity. For our purposes we only used CH0 in Pamguard to run the detector. To view the Array Configuration files for each drift please click here* (insert link to storage place)\n\n\n\nFigure X. Array settings in Pamguard\n\n\n\n\n\n\n\nThe Decimator in PAMGuard was set to decimate to 200Hz. Default filter settings were used.\n\n\n\nThe Decimator in PAMGuard was set to decimate to 200Hz. Default filter settings were used.\n\n\n\nThe Decimator in PAMGuard was set to decimate to 10kHz and used a Butterworth Low Pass Filter of 5kHz .\n\n\n\n\n\n\n\nFor humpback and gray whales we decimated files to 10kHz (Figure X.) and used a Butterworth Low Pass Filter of 5kHz (Figure x).\n\n\n\nFigure x. Settings used in the decimator module in Pamguard to run the humpback and gray whale GPL detector.\n\n\n\n\n\nFigure x. Low Pass Filter for Humback and Gray whale GPL detector\n\n\n\n\n\n\n\n\nIn order to detect 20Hz fin whale pulses, we ran a click detector in PAMGuard.\n\n\nClick detection parameters were set to the following (see figures x-xx)\n\n\n\n\n\nFigure x. Source information for the click detector\n\n\n\n\n\nFigure X. Trigger settings for the Click Detector\n\n\n\n\n\nFigure X. Click length settings for the click detector\n\n\n\n\n\nFigure x. Delays settings for the click detector\n\n\n\n\n\nFigure x. Echo settings for the click detector\n\n\n\n\n\nFigure x. Noise settings for the click detector\n\n\n\n\n\n\n\n\n\nFigure x. Digital Pre Filter Settings\n\n\n\n\n\n\n\n\nFigure x. Digital Trigger Filter Settings\n\n\n\n\n\n\n\nA click classifier with a frequency sweep was set up in order to classify the fin whale 20Hz pulses. The setting are below in Figure x. For the classifier itself, only the Spectrum Tab settings were changed. The rest of the tabs were left as default.\n\n\n\n\nFigure x. Click classification general settings\n\n\n\n\n\nFigure x. Click classifier settings.\n\n\n\nOnce these settings have been input into the previous modules, make sure to save the settings file using the Data Managment Google Doc as a guide. The naming scheme should have the PG version_DetectorType_Project_Deployment#.\n\nEx. PG_2_02_02_FinClick_ADRIFT_049.psfx\n\nRun all drifts with the same settings.\n\n\n\n\n\n\nOnce a drift has completed its run. Save and close PAMGuard.\nMake a copy of the database that was run and place it in a new folder (this is the copy that you will be adding events to).\nOpen the database in PAMGuard Viewer Mode\n\nAdd the spectrogrm annotation module (figure x)\n\n\n\n\n\nFigure X. Adding the spectrogram annotation module\n\n\n\nAdd a new user form under the spectrogram annotation module by clicking on the settings gear icon.\n\n\n\n\nFigure x. Creating a new logger form within the spectrogram annotation module\n\n\n\nEdit the form and add a LookUp table with the following titles\n\n\n\n\nFigure X. Creating a Lookup Table\n\n\n\nIn the lookup editor, add in the four categories to annotate the spectrogram module with.\n\n\n\n\nFigure X. Editing the lookup table so the following dropdowns are present. 20Hz_fin, possible_fin, anthropogenic, unknown_biological.\n\n\n\nClick ok on all the open dialog boxes. Click file-&gt;save data.\nClose PAMGuard Viewer Mode and re-open to see the drop down options you created.\n\n\n\n\n\nWe started with basic GPL settings from Tyler Helble’s PARM files and modified them to fit our data\nWe tested modified settings on clips that contained our species of interest until we were happy with the detectors performance\nWe then processed an entire drift’s recordings and looked at the detector’s performance in Pamguard Viewer Mode by spot checking that calls were being picked up by the detector\nOnce we were satisfied that the detector was doing it’s job, we processed the rest of the drifts\nFor this detector, our aim was to over-detect and then sort out the differences using a classifier\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure X. GPL FFT Settings for humpback and gray whales\n\n\n\n\n\nFigure x. GPL detections settings for humpback and gray whales\n\n\n\n\n\nFigure x. GPL contour settings for humpback and gray whales\n\n\n\n\n\n\n\nIn order for PAMpal to interact with the GPL detections we added in the Detection Grouper Module. This allows PAMpal to create events and push them back in the SQLite database in PAMGuard.\n\n\n\nFigure x. Detection Grouper Mark Display Settings\n\n\n\n\n\nFigure X. Detection Grouper Data Selection Settings\n\n\n\n\n\nFigure x. Detection Grouper Annotation Settings\n\n\nIt is important to note that both the “Text” and “User Form” annotation boxes must be selected here.\n\nTo setup the user form annotation (click on the gear icon)\nCreate new user form\nLabel the form “evType” then click ok (see figure X)\n\n\n\nFigure x. Adding in a user form for the Detection Grouper in Pamguard\n\n\nNext click “edit form”\nAdd a lookup table and fill it out exactly as follows (see figure x.)\n\nTitle: eventType\nPostTitle: eventType\nDbTitle: eventType\nTopic: DGEventType\n\n\n\nFigure x. Editing the user form for the detection grouper to work with the GPL detections\n\n\n\nAdd selection drop down by right clicking on ‘= no selection =’ and selecting ‘Edit list’\n\nClick ‘Add item’ and fill in species specific options\n\nSee ‘Species Specific Drop Down List’ below for what items to include\n\n\nClick ‘Ok’ to close all of the tabs and return to Pamguard Viewer window\n\nNext, set up the Spectrogram Annotation\n\nGo to File &gt; Add Modules &gt; Utilities &gt; Spectrogram Annotation\n\nUnder ‘Settings’, go to Spectrogram Annotation settings and click on the gear icon next to ‘User form annotation’\nClick on the ‘User form’ drop down, select ‘UDF_evType’, and click Ok to return to the Pamguard Viewer window\n\n\nRight click on the spectrogram and go to Settings\n\nEnsure both the ‘Detection Grouper’ and ‘Spectrogram Annotation’ boxes are checked and click Ok\n\n\nGo to File &gt; Save Data and close Pamguard\n\n\n\n\n\n\n\n\n\nB - Boing\nCB - Cutoff Boing\nUB - Unknown Biological Sound\nUA - Unknown Anthropogenic Sound\n\n\n\n\n\n\n\n\n\n\n\nAll detections were saved to the binary files and all other data were saved to a SQLite database\n\n\n\nFigure x. Storage Options Settings for PAMGuard"
  },
  {
    "objectID": "content/BaleenWhales/Dectections.html#array",
    "href": "content/BaleenWhales/Dectections.html#array",
    "title": "Detection",
    "section": "",
    "text": "Depending on the drift that was processed, the array settings in Pamguard were updated to reflect the spacing between hydrophones and the hydrophone sensitivity. For our purposes we only used CH0 in Pamguard to run the detector. To view the Array Configuration files for each drift please click here* (insert link to storage place)\n\n\n\nFigure X. Array settings in Pamguard"
  },
  {
    "objectID": "content/BaleenWhales/Dectections.html#decimation",
    "href": "content/BaleenWhales/Dectections.html#decimation",
    "title": "Detection",
    "section": "",
    "text": "The Decimator in PAMGuard was set to decimate to 200Hz. Default filter settings were used.\n\n\n\nThe Decimator in PAMGuard was set to decimate to 200Hz. Default filter settings were used.\n\n\n\nThe Decimator in PAMGuard was set to decimate to 10kHz and used a Butterworth Low Pass Filter of 5kHz .\n\n\n\n\n\n\n\nFor humpback and gray whales we decimated files to 10kHz (Figure X.) and used a Butterworth Low Pass Filter of 5kHz (Figure x).\n\n\n\nFigure x. Settings used in the decimator module in Pamguard to run the humpback and gray whale GPL detector.\n\n\n\n\n\nFigure x. Low Pass Filter for Humback and Gray whale GPL detector"
  },
  {
    "objectID": "content/BaleenWhales/Dectections.html#fin-whale-click-detector",
    "href": "content/BaleenWhales/Dectections.html#fin-whale-click-detector",
    "title": "Detection",
    "section": "",
    "text": "In order to detect 20Hz fin whale pulses, we ran a click detector in PAMGuard.\n\n\nClick detection parameters were set to the following (see figures x-xx)\n\n\n\n\n\nFigure x. Source information for the click detector\n\n\n\n\n\nFigure X. Trigger settings for the Click Detector\n\n\n\n\n\nFigure X. Click length settings for the click detector\n\n\n\n\n\nFigure x. Delays settings for the click detector\n\n\n\n\n\nFigure x. Echo settings for the click detector\n\n\n\n\n\nFigure x. Noise settings for the click detector\n\n\n\n\n\n\n\n\n\nFigure x. Digital Pre Filter Settings\n\n\n\n\n\n\n\n\nFigure x. Digital Trigger Filter Settings\n\n\n\n\n\n\n\nA click classifier with a frequency sweep was set up in order to classify the fin whale 20Hz pulses. The setting are below in Figure x. For the classifier itself, only the Spectrum Tab settings were changed. The rest of the tabs were left as default.\n\n\n\n\nFigure x. Click classification general settings\n\n\n\n\n\nFigure x. Click classifier settings.\n\n\n\nOnce these settings have been input into the previous modules, make sure to save the settings file using the Data Managment Google Doc as a guide. The naming scheme should have the PG version_DetectorType_Project_Deployment#.\n\nEx. PG_2_02_02_FinClick_ADRIFT_049.psfx\n\nRun all drifts with the same settings."
  },
  {
    "objectID": "content/BaleenWhales/Dectections.html#spectrogram-annotation-setup",
    "href": "content/BaleenWhales/Dectections.html#spectrogram-annotation-setup",
    "title": "Detection",
    "section": "",
    "text": "Once a drift has completed its run. Save and close PAMGuard.\nMake a copy of the database that was run and place it in a new folder (this is the copy that you will be adding events to).\nOpen the database in PAMGuard Viewer Mode\n\nAdd the spectrogrm annotation module (figure x)\n\n\n\n\n\nFigure X. Adding the spectrogram annotation module\n\n\n\nAdd a new user form under the spectrogram annotation module by clicking on the settings gear icon.\n\n\n\n\nFigure x. Creating a new logger form within the spectrogram annotation module\n\n\n\nEdit the form and add a LookUp table with the following titles\n\n\n\n\nFigure X. Creating a Lookup Table\n\n\n\nIn the lookup editor, add in the four categories to annotate the spectrogram module with.\n\n\n\n\nFigure X. Editing the lookup table so the following dropdowns are present. 20Hz_fin, possible_fin, anthropogenic, unknown_biological.\n\n\n\nClick ok on all the open dialog boxes. Click file-&gt;save data.\nClose PAMGuard Viewer Mode and re-open to see the drop down options you created."
  },
  {
    "objectID": "content/BaleenWhales/Dectections.html#gpl-settings",
    "href": "content/BaleenWhales/Dectections.html#gpl-settings",
    "title": "Detection",
    "section": "",
    "text": "We started with basic GPL settings from Tyler Helble’s PARM files and modified them to fit our data\nWe tested modified settings on clips that contained our species of interest until we were happy with the detectors performance\nWe then processed an entire drift’s recordings and looked at the detector’s performance in Pamguard Viewer Mode by spot checking that calls were being picked up by the detector\nOnce we were satisfied that the detector was doing it’s job, we processed the rest of the drifts\nFor this detector, our aim was to over-detect and then sort out the differences using a classifier\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure X. GPL FFT Settings for humpback and gray whales\n\n\n\n\n\nFigure x. GPL detections settings for humpback and gray whales\n\n\n\n\n\nFigure x. GPL contour settings for humpback and gray whales"
  },
  {
    "objectID": "content/BaleenWhales/Dectections.html#detection-group-localizer-settings-gpl-only",
    "href": "content/BaleenWhales/Dectections.html#detection-group-localizer-settings-gpl-only",
    "title": "Detection",
    "section": "",
    "text": "In order for PAMpal to interact with the GPL detections we added in the Detection Grouper Module. This allows PAMpal to create events and push them back in the SQLite database in PAMGuard.\n\n\n\nFigure x. Detection Grouper Mark Display Settings\n\n\n\n\n\nFigure X. Detection Grouper Data Selection Settings\n\n\n\n\n\nFigure x. Detection Grouper Annotation Settings\n\n\nIt is important to note that both the “Text” and “User Form” annotation boxes must be selected here.\n\nTo setup the user form annotation (click on the gear icon)\nCreate new user form\nLabel the form “evType” then click ok (see figure X)\n\n\n\nFigure x. Adding in a user form for the Detection Grouper in Pamguard\n\n\nNext click “edit form”\nAdd a lookup table and fill it out exactly as follows (see figure x.)\n\nTitle: eventType\nPostTitle: eventType\nDbTitle: eventType\nTopic: DGEventType\n\n\n\nFigure x. Editing the user form for the detection grouper to work with the GPL detections\n\n\n\nAdd selection drop down by right clicking on ‘= no selection =’ and selecting ‘Edit list’\n\nClick ‘Add item’ and fill in species specific options\n\nSee ‘Species Specific Drop Down List’ below for what items to include\n\n\nClick ‘Ok’ to close all of the tabs and return to Pamguard Viewer window\n\nNext, set up the Spectrogram Annotation\n\nGo to File &gt; Add Modules &gt; Utilities &gt; Spectrogram Annotation\n\nUnder ‘Settings’, go to Spectrogram Annotation settings and click on the gear icon next to ‘User form annotation’\nClick on the ‘User form’ drop down, select ‘UDF_evType’, and click Ok to return to the Pamguard Viewer window\n\n\nRight click on the spectrogram and go to Settings\n\nEnsure both the ‘Detection Grouper’ and ‘Spectrogram Annotation’ boxes are checked and click Ok\n\n\nGo to File &gt; Save Data and close Pamguard\n\n\n\n\n\n\n\n\n\nB - Boing\nCB - Cutoff Boing\nUB - Unknown Biological Sound\nUA - Unknown Anthropogenic Sound\n\n\n\n\n\n\n\n\n\n\n\nAll detections were saved to the binary files and all other data were saved to a SQLite database\n\n\n\nFigure x. Storage Options Settings for PAMGuard"
  },
  {
    "objectID": "content/BaleenWhales/Dectections.html#species-specific-validation-methods",
    "href": "content/BaleenWhales/Dectections.html#species-specific-validation-methods",
    "title": "Detection",
    "section": "Species Specific Validation Methods",
    "text": "Species Specific Validation Methods\n\nFin Whales\n\n\nBlue Whales\n\n\nMinke Whales\n\nMethod for boings cutoff at the start or end of file (only applies to subsampled data to be validated)\n\nIf the detector consistently picks up cutoff boings AND you think they can be picked up easily using manual effort (there is enough signal to know it is a boing) -- then box these partial detections and label them as ‘Cutoff Boing’ (can be helpful as they note the occurrence of these calls during this time selection)\n\nThe box should go to absolute zero (hug that left edge), as we can later use this demarcation to identify potential calls that are incomplete (if that is important for downstream processing)\n\n\nMethod for false dectections\n\nIgnore them\n\n\n\n\nBrydes & Fin Whales (40 Hz)\n\n\nHumpback & Gray Whales"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Adrift Analysis Methods",
    "section": "",
    "text": "This document provides information related to data analysis for ADRIFT in the California Current, which uses drifting acoustic recorders to monitor marine mammals and ocean soundscapes. These methods include tasks related to data preparation and archiving, detection and classification of baleen and toothed whales, and the characterization of ocean soundscapes.",
    "crumbs": [
      "Home"
    ]
  },
  {
    "objectID": "content/BaleenWhales/MinkeWhales.html",
    "href": "content/BaleenWhales/MinkeWhales.html",
    "title": "Minke Whales",
    "section": "",
    "text": "All drifts used a default Pamguard settings file. To view an example Pamguard settings file please click here (insert link to GitHub repository). Open Pamguard settings file and save each drift under a new .psfx as ADRIFT_###_PGversion_Minke (ADRIFT_001_PG_2_02_02_Minke.psfx)\nA Generalized Power Law detector was used to detect Minke boings (figure X). We started with basic GPL settings from Tyler Helble’s PARM files and modified them to fit our data. Exact parameters are detailed below.\n\n\n\nFigure X. Spectrogram of Minke whale boings being detected by GPL detector\n\n\n\n\nSet database path to a new blank database titled ADRIFT_###_PG_2_02_02_Minke.sqlite3\n\n\n\nCreate a new binary folder for your detections titled ADRIFT_###_PG_2_02_02_Minke\n\n\n\nDepending on the drift that was processed, the array settings in Pamguard were updated to reflect the spacing between hydrophones and the hydrophone sensitivity. For our purposes we only used CH0 in Pamguard to run the detector. To view the Array Configuration files for each drift please click here* (insert link to storage place)\n\n\n\nSet the sound acquisition path to the folder your sound files are in\n\n\n\nhe Decimator in PAMGuard was set to decimate to 10kHz and used a Butterworth Low Pass Filter of 5kHz .\n\n\n\n\n\n\n\n\n\n\nIn order for PAMpal to interact with the GPL detections we added in the Detection Grouper Module. This allows PAMpal to create events and push them back in the SQLite database in PAMGuard.\n\n\n\n\nFigure x. Detection Grouper Mark Display Settings\n\n\n\n\n\nFigure X. Detection Grouper Data Selection Settings\n\n\n\n\n\nFigure x. Detection Grouper Annotation Settings\n\n\n\nIt is important to note that both the “Text” and “User Form” annotation boxes must be selected here.\n\nTo setup the user form annotation (click on the gear icon)\nCreate new user form\nLabel the form “evType” then click ok (see figure X)\n\n\n\nFigure x. Adding in a user form for the Detection Grouper in Pamguard\n\n\nNext click “edit form”\nAdd a lookup table and fill it out exactly as follows (see figure x.)\n\nTitle: eventType\nPostTitle: eventType\nDbTitle: eventType\nTopic: DGEventType\n\n\n\nFigure x. Editing the user form for the detection grouper to work with the GPL detections\n\n\nAdd selection drop down by right clicking on ‘= no selection =’ and selecting ‘Edit list’\n\n\n\n\n\nClick ‘Add item’ and fill in species specific options\n\nB - Boing\nCB - Cutoff Boing\nUB - Unknown Biological Sound\nUA - Unknown Anthropogenic Sound\n\n\n\n\nClick ‘Ok’ to close all of the tabs and return to Pamguard Viewer window\nNext, set up the Spectrogram Annotation\n\nGo to File &gt; Add Modules &gt; Utilities &gt; Spectrogram Annotation\n\n\nUnder ‘Settings’, go to Spectrogram Annotation settings and click on the gear icon next to ‘User form annotation’\nClick on the ‘User form’ drop down, select ‘UDF_evType’, and click Ok to return to the Pamguard Viewer window\n\nRight click on the spectrogram and go to Settings\n\nEnsure both the ‘Detection Grouper’ and ‘Spectrogram Annotation’ boxes are checked and click Ok\n\n\nGo to File &gt; Save Data and close Pamguard"
  },
  {
    "objectID": "content/BaleenWhales/MinkeWhales.html#pamguard-set-up",
    "href": "content/BaleenWhales/MinkeWhales.html#pamguard-set-up",
    "title": "Minke Whales",
    "section": "",
    "text": "All drifts used a default Pamguard settings file. To view an example Pamguard settings file please click here (insert link to GitHub repository). Open Pamguard settings file and save each drift under a new .psfx as ADRIFT_###_PGversion_Minke (ADRIFT_001_PG_2_02_02_Minke.psfx)\nA Generalized Power Law detector was used to detect Minke boings (figure X). We started with basic GPL settings from Tyler Helble’s PARM files and modified them to fit our data. Exact parameters are detailed below.\n\n\n\nFigure X. Spectrogram of Minke whale boings being detected by GPL detector\n\n\n\n\nSet database path to a new blank database titled ADRIFT_###_PG_2_02_02_Minke.sqlite3\n\n\n\nCreate a new binary folder for your detections titled ADRIFT_###_PG_2_02_02_Minke\n\n\n\nDepending on the drift that was processed, the array settings in Pamguard were updated to reflect the spacing between hydrophones and the hydrophone sensitivity. For our purposes we only used CH0 in Pamguard to run the detector. To view the Array Configuration files for each drift please click here* (insert link to storage place)\n\n\n\nSet the sound acquisition path to the folder your sound files are in\n\n\n\nhe Decimator in PAMGuard was set to decimate to 10kHz and used a Butterworth Low Pass Filter of 5kHz .\n\n\n\n\n\n\n\n\n\n\nIn order for PAMpal to interact with the GPL detections we added in the Detection Grouper Module. This allows PAMpal to create events and push them back in the SQLite database in PAMGuard.\n\n\n\n\nFigure x. Detection Grouper Mark Display Settings\n\n\n\n\n\nFigure X. Detection Grouper Data Selection Settings\n\n\n\n\n\nFigure x. Detection Grouper Annotation Settings\n\n\n\nIt is important to note that both the “Text” and “User Form” annotation boxes must be selected here.\n\nTo setup the user form annotation (click on the gear icon)\nCreate new user form\nLabel the form “evType” then click ok (see figure X)\n\n\n\nFigure x. Adding in a user form for the Detection Grouper in Pamguard\n\n\nNext click “edit form”\nAdd a lookup table and fill it out exactly as follows (see figure x.)\n\nTitle: eventType\nPostTitle: eventType\nDbTitle: eventType\nTopic: DGEventType\n\n\n\nFigure x. Editing the user form for the detection grouper to work with the GPL detections\n\n\nAdd selection drop down by right clicking on ‘= no selection =’ and selecting ‘Edit list’\n\n\n\n\n\nClick ‘Add item’ and fill in species specific options\n\nB - Boing\nCB - Cutoff Boing\nUB - Unknown Biological Sound\nUA - Unknown Anthropogenic Sound\n\n\n\n\nClick ‘Ok’ to close all of the tabs and return to Pamguard Viewer window\nNext, set up the Spectrogram Annotation\n\nGo to File &gt; Add Modules &gt; Utilities &gt; Spectrogram Annotation\n\n\nUnder ‘Settings’, go to Spectrogram Annotation settings and click on the gear icon next to ‘User form annotation’\nClick on the ‘User form’ drop down, select ‘UDF_evType’, and click Ok to return to the Pamguard Viewer window\n\nRight click on the spectrogram and go to Settings\n\nEnsure both the ‘Detection Grouper’ and ‘Spectrogram Annotation’ boxes are checked and click Ok\n\n\nGo to File &gt; Save Data and close Pamguard"
  },
  {
    "objectID": "content/BaleenWhales/MinkeWhales.html#detection-validation",
    "href": "content/BaleenWhales/MinkeWhales.html#detection-validation",
    "title": "Minke Whales",
    "section": "Detection Validation",
    "text": "Detection Validation\nManually validate all detections to look for Minke boings"
  },
  {
    "objectID": "content/BaleenWhales/MinkeWhales.html#all-data-validation",
    "href": "content/BaleenWhales/MinkeWhales.html#all-data-validation",
    "title": "Minke Whales",
    "section": "All Data Validation",
    "text": "All Data Validation\n\nDue to the nature of this large data set we decided to use a stratified sub-sampling method to randomly sample 20% of all events for validation.\n\n\n*Add in Kaitlin’s code\n\n# PAMpal simple example \n# Its on CRAN. Yay!\n# install.packages('PAMpal')\n# Sometimes I fix things and theyre only available on the GitHub version\n# Right now there are some things that run a lot faster on teh GitHub version so I recommend installing that.\n# updated 22-12-6 to include loop for PG event adding w/PAMmisc\nrm(list=ls())\ndevtools::install_github('TaikiSan21/PAMpal')\ndevtools::install_github('TaikiSan21/PAMmisc')\nlibrary(PAMpal)\nlibrary(PAMmisc)\n\n# Start by creating a \"PAMpalSettings\" object. This keeps track of what data you want to process and what processing you want to apply to it.\n\n# Change paths below to your DB and binary folder. Can just be the highest level binary folder for that drift - it will add all files within that folder recursively through subfolders.\n\n# This will also ask you to type in some parameters for calculations in your console. You can just hit ENTER to accept defaults for all of these, they aren't relevant to the GPL calculations only for clicks.\n\npps &lt;- PAMpalSettings(db = 'Path to database',\n                      binaries = 'Path to binaries',\n                      # these parameters are only for the click detector - can ignroe\n                      sr_hz='auto',\n                      filterfrom_khz=0,\n                      filterto_khz=NULL,\n                      winLen_sec=.0025)\n\n# Now tell it to process your data. Id is optional and serves no function, but can be useful to tell data apart at a later point in time. Here mode = 'recording' tells it how to organize your data. Most of the time we are working with data that have been marked manually into events, so PAMpal wants to organize things into events. mode='db' uses the events in the database, and only processes the detectoins you've marked out. In this case we just want to process everything, which is what mode='recording' does. It will group them into events by recording file. \n\n# This might take some time to read in events after processing in order to get the time \n#data &lt;- processPgDetections(pps, mode='db', id='Minke_CCES_019') \n\ndata &lt;- processPgDetections(pps, mode='recording', id='Species_Project_Drift#')\n\n# And here's how you can get the detections information out of \"data\" as a dataframe. Time column is \"UTC\", other columns are stuff it measured. \ngplDf &lt;- getGPLData(data)\n\n# Now we can add the wav files to this data. You might get a warning about \"startSample\", its safe to ignore that.\ndata &lt;- addRecordings(data, \n                      folder='Path to wav files')\n\n# that data is stored here as a dataframe. Has \"start\" & \"end\" as POSIXct and the fulle path to the file as \"file\"\nwavDf &lt;- files(data)$recordings\n\n# add number of detections to this\nnDets &lt;- sapply(events(data), nDetections)\nnDets &lt;- data.frame(join=names(nDets), nDets=nDets)\nwavDf$join &lt;- basename(wavDf$file)\nwavDf &lt;- left_join(wavDf, nDets)\nwavDf$join &lt;- NULL\nwavDf$nDets[is.na(wavDf$nDets)] &lt;- 0\n\nnfiles =round(nrow(wavDf)*.2)\nrandStart =sample(1:5,1)\n\nwavDf=wavDf[round(seq(randStart, nrow(wavDf), length.out = nfiles)),]\n\n# If we care about assigning some kind of initial label to these detections. Otherwise ignore. \ndata &lt;- setSpecies(data, method='manual', value='InitialGPL')\n\n# Add events from wavDf loop\nfor(e in 1:nrow(wavDf)) {\n  thisEv &lt;- data[[basename(wavDf$file[e])]]\n  # this will get all detector types, if just one type is wanted can be simplified to ex. uids &lt;- unique(getGPLData(thisEv)$UID)\n  uids &lt;- unique(unlist(lapply(getDetectorData(thisEv), function(x) {\n    if(is.null(x)) return(NULL)\n    x$UID\n  })))\n  \n  addPgEvent(db = files(thisEv)$db,\n             binary = files(thisEv)$binaries,\n             eventType = species(thisEv)$id,\n             UIDs = uids,\n             type = 'dg',\n             start = wavDf$start[e],\n             end = wavDf$end[e],\n             comment = paste0('Added by PAMpal, event ID: ', id(thisEv)))\n}\n\n\n\nValidation\n\nOnce you have followed the code above to subsample your data, make a copy of the database in a ‘Data Validated’ folder and reopen the database in Pamguard Viewer\nGo to File &gt; Add Modules &gt; Displays &gt; User Display\n\nName the new user display ‘Subsample’\nClick on the new subsample tab and go to User Display &gt; New Detection Grouper data display\n\nYour subsampled data should then be listed with associate marker colors\n\nValidate each subsampled wav file by scrolling in the spectrogram to the file and boxing/validating all detections using the drop down options specified above\n\n\n\nNotes\n\nMethod for boings cutoff at the start or end of file (only applies to subsampled data to be validated)\n\nIf the detector consistently picks up cutoff boings AND you think they can be picked up easily using manual effort (there is enough signal to know it is a boing) -- then box these partial detections and label them as ‘Cutoff Boing’ (can be helpful as they note the occurrence of these calls during this time selection)\n\nThe box should go to absolute zero (hug that left edge), as we can later use this demarcation to identify potential calls that are incomplete (if that is important for downstream processing)\n\n\nMethod for false dectections\n\nIgnore them"
  },
  {
    "objectID": "content/BaleenWhales/Slides/methodsforloggingbaleenwhales.html#step-1-open-matlab-and-set-the-path",
    "href": "content/BaleenWhales/Slides/methodsforloggingbaleenwhales.html#step-1-open-matlab-and-set-the-path",
    "title": "Methods for Logging Baleen Whales SWFSC",
    "section": "Step 1: Open Matlab and Set the Path",
    "text": "Step 1: Open Matlab and Set the Path\n\n\n\nCurrently we are using Matlab 2023a\nClick on the home tab -&gt;Environment-&gt;Set Path\nClick “Add folder with Subfolders…”\nBrowse to the folder containing Triton-R2020\nClick “Save” and then “Close"
  },
  {
    "objectID": "content/BaleenWhales/Slides/methodsforloggingbaleenwhales.html#step-2-open-triton",
    "href": "content/BaleenWhales/Slides/methodsforloggingbaleenwhales.html#step-2-open-triton",
    "title": "Methods for Logging Baleen Whales SWFSC",
    "section": "Step 2: Open Triton",
    "text": "Step 2: Open Triton\n\n\n\nStart Matlab and at the command prompt type ‘triton’ and press enter to run the application\nThree windows will be displayed: Plot, Control, & Message…"
  },
  {
    "objectID": "content/BaleenWhales/Slides/methodsforloggingbaleenwhales.html#step-3-add-logger-remora",
    "href": "content/BaleenWhales/Slides/methodsforloggingbaleenwhales.html#step-3-add-logger-remora",
    "title": "Methods for Logging Baleen Whales SWFSC",
    "section": "Step 3: Add Logger Remora",
    "text": "Step 3: Add Logger Remora\n\n\n\nIn the control window (upper left hand window) click on ‘Remoras’ then ’Add Remora.”\nBrowse to the folder containing Triton-&gt;Remoras-&gt;Logger. Highlight this folder and click ‘Select Folder’\nA new window pop up asking to restart Triton, click ‘Yes’\nYou will only need to add the Remora once. Triton should remember this once you have added it. It will prompt you to restart Triton at this time."
  },
  {
    "objectID": "content/BaleenWhales/Slides/methodsforloggingbaleenwhales.html#step-4-open-an-ltsa",
    "href": "content/BaleenWhales/Slides/methodsforloggingbaleenwhales.html#step-4-open-an-ltsa",
    "title": "Methods for Logging Baleen Whales SWFSC",
    "section": "Step 4: Open an LTSA",
    "text": "Step 4: Open an LTSA\n\n\n\nClick File-&gt;Open LTSA\nBrowse to the LTSA you wish to use for your log (they may vary depending on the species you are logging). Blue and Fin whales were logged using 500Hz LTSAs\nWhen it opens the plot and control windows may look something like this"
  },
  {
    "objectID": "content/BaleenWhales/Slides/methodsforloggingbaleenwhales.html#step-5-set-parameters",
    "href": "content/BaleenWhales/Slides/methodsforloggingbaleenwhales.html#step-5-set-parameters",
    "title": "Methods for Logging Baleen Whales SWFSC",
    "section": "Step 5: Set Parameters",
    "text": "Step 5: Set Parameters\n\n\n\nIf you are logging duty cycled data you will want to be looking at around 1 hour at a time. Set the plot length accordingly.\nIf you are logging continuous data then plot length should be 1\nMake sure you start logging as close to the start of the hour as possible\nBrightness should be from 0-10dB\nContrast should be around 100dB\nDepending on the species you will want to adjust your upper frequency bounds.\n\nFor blue and fin whales you can look at 0-150Hz"
  },
  {
    "objectID": "content/BaleenWhales/Slides/methodsforloggingbaleenwhales.html#step-6-create-a-new-log",
    "href": "content/BaleenWhales/Slides/methodsforloggingbaleenwhales.html#step-6-create-a-new-log",
    "title": "Methods for Logging Baleen Whales SWFSC",
    "section": "Step 6: Create a New Log",
    "text": "Step 6: Create a New Log\n\n\n\nClick on Remoras-&gt;Log-&gt;New Log\nEnter in the name of the log and direct Triton to save it in the folder with the LTSA\nName your log with the Cruise_Year_Drift_#_Species_Log\n\nEx: CCES_2018_Drift_07_BlueWhale_Log"
  },
  {
    "objectID": "content/BaleenWhales/Slides/methodsforloggingbaleenwhales.html#step-7-set-the-deployment-metadata",
    "href": "content/BaleenWhales/Slides/methodsforloggingbaleenwhales.html#step-7-set-the-deployment-metadata",
    "title": "Methods for Logging Baleen Whales SWFSC",
    "section": "Step 7: Set the deployment metadata",
    "text": "Step 7: Set the deployment metadata\n\n\n\nType your initials in the ‘User ID’ tab\nType the project name in the ‘Project’ tab\nType in the Drift number in “Deployment’ and ‘Site’ tabs\nThen select your start time on the LTSA.\n\nRemember to make sure to start as close to the hour as possible\nClick ‘Set deployment metadata’"
  },
  {
    "objectID": "content/BaleenWhales/Slides/methodsforloggingbaleenwhales.html#step-8-setting-up-logging-options",
    "href": "content/BaleenWhales/Slides/methodsforloggingbaleenwhales.html#step-8-setting-up-logging-options",
    "title": "Methods for Logging Baleen Whales SWFSC",
    "section": "Step 8: Setting up logging options",
    "text": "Step 8: Setting up logging options\n\n\n\nCheck ‘All’ under the logging options\n\nYou can double click the “All’ button to expand it and check off specific species if you want.\n\nUnder Granularity select ‘binned’\nUnder time in minutes type ’60\nClick ‘Set Effort’\n\nNOTE: Although your log is open in the background do not make changes to it. If you need to make a change to your spreadsheet you must end your logging session and then open the spreadsheet to make changes."
  },
  {
    "objectID": "content/BaleenWhales/Slides/methodsforloggingbaleenwhales.html#step-9-scrolling-and-looking-for-calls",
    "href": "content/BaleenWhales/Slides/methodsforloggingbaleenwhales.html#step-9-scrolling-and-looking-for-calls",
    "title": "Methods for Logging Baleen Whales SWFSC",
    "section": "Step 9: Scrolling and looking for calls",
    "text": "Step 9: Scrolling and looking for calls\n\n\n\nUse the arrows on the LTSA to scroll back and forward in time\nLook for spikes of energy in the LTSA\n\nThese are Blue whale D calls with low frequency noise"
  },
  {
    "objectID": "content/BaleenWhales/Slides/methodsforloggingbaleenwhales.html#step-10-zooming-in-on-a-sound",
    "href": "content/BaleenWhales/Slides/methodsforloggingbaleenwhales.html#step-10-zooming-in-on-a-sound",
    "title": "Methods for Logging Baleen Whales SWFSC",
    "section": "Step 10: Zooming in on a sound",
    "text": "Step 10: Zooming in on a sound\n\n\n\nWhen you see a spike of energy that you want to investigate click on the ‘Expand’ button to open the associated wav file\nThen click on the part of the LTSA that you want to look at in more detail"
  },
  {
    "objectID": "content/BaleenWhales/Slides/methodsforloggingbaleenwhales.html#step-11-adjust-spectrogram-parameters",
    "href": "content/BaleenWhales/Slides/methodsforloggingbaleenwhales.html#step-11-adjust-spectrogram-parameters",
    "title": "Methods for Logging Baleen Whales SWFSC",
    "section": "Step 11: Adjust Spectrogram Parameters",
    "text": "Step 11: Adjust Spectrogram Parameters\n\n\n\nSet the plot length to 120 s. If it wont let you set it that high then use the back arrow to scroll to the beginning of the wav file\nSet the Plot Freq End to 200 Hz. We are looking for calls generally below 100 Hz.\nFFT will vary depending on the frequency range you are looking at. For blue and fin whales we will use 512\nSet %Overlap to 90\nBrightness should be between 0-10dB\nContrast should be around 100%dB"
  },
  {
    "objectID": "content/BaleenWhales/Slides/methodsforloggingbaleenwhales.html#now-you-triton-windows-should-look-something-like-this",
    "href": "content/BaleenWhales/Slides/methodsforloggingbaleenwhales.html#now-you-triton-windows-should-look-something-like-this",
    "title": "Methods for Logging Baleen Whales SWFSC",
    "section": "Now you Triton windows should look something like this",
    "text": "Now you Triton windows should look something like this"
  },
  {
    "objectID": "content/BaleenWhales/Slides/methodsforloggingbaleenwhales.html#step-12-logging-your-first-sound",
    "href": "content/BaleenWhales/Slides/methodsforloggingbaleenwhales.html#step-12-logging-your-first-sound",
    "title": "Methods for Logging Baleen Whales SWFSC",
    "section": "Step 12: Logging your first sound",
    "text": "Step 12: Logging your first sound\n\nGo through each hour of recordings and look for calls made by the species of interest (i.e. blue whale A, B and D calls)\nWe will be binning call types by the hour\nWhen you find your first call we you click on the corresponding drop down for group and species\nThen check off the first call of that type you have seen in that hour\nClick on the call and then click on “pick start”\n*In the comments please note the quality of the call (1-3) followed by the quality of the recordings (G or B). PLEASE SEPARATE USING A “,” (comma)\n\n1=low SNR (signal to noise ratio)\n2=medium SNR\n3=high SNR\nG=good and can use auto-detector\nB=bad and cannot use auto-detector\n\nClick log to save the information to the spreadsheet\n\n*See more on this on following slides"
  },
  {
    "objectID": "content/BaleenWhales/Slides/methodsforloggingbaleenwhales.html#unsure-about-the-species-or-call-type",
    "href": "content/BaleenWhales/Slides/methodsforloggingbaleenwhales.html#unsure-about-the-species-or-call-type",
    "title": "Methods for Logging Baleen Whales SWFSC",
    "section": "Unsure about the species or call type?",
    "text": "Unsure about the species or call type?\n\nListen to the sound. Does is sound like the call type you are logging?\nCheck in with Cory or Shannon. If they are busy or aren’t sure of the call type either then…\nSave the image and audio\nIn the comments box type “poss call type” (ie poss B call) after the SNR of the call and the G/B recording. Separate these using a comma. We will review these later\n\nIe : 3, G, poss B call"
  },
  {
    "objectID": "content/BaleenWhales/Slides/methodsforloggingbaleenwhales.html#examples-of-snr-1-calls",
    "href": "content/BaleenWhales/Slides/methodsforloggingbaleenwhales.html#examples-of-snr-1-calls",
    "title": "Methods for Logging Baleen Whales SWFSC",
    "section": "Examples of SNR 1 Calls",
    "text": "Examples of SNR 1 Calls"
  },
  {
    "objectID": "content/BaleenWhales/Slides/methodsforloggingbaleenwhales.html#examples-of-snr-2-calls",
    "href": "content/BaleenWhales/Slides/methodsforloggingbaleenwhales.html#examples-of-snr-2-calls",
    "title": "Methods for Logging Baleen Whales SWFSC",
    "section": "Examples of SNR 2 Calls",
    "text": "Examples of SNR 2 Calls"
  },
  {
    "objectID": "content/BaleenWhales/Slides/methodsforloggingbaleenwhales.html#examples-of-snr-3-calls",
    "href": "content/BaleenWhales/Slides/methodsforloggingbaleenwhales.html#examples-of-snr-3-calls",
    "title": "Methods for Logging Baleen Whales SWFSC",
    "section": "Examples of SNR 3 Calls",
    "text": "Examples of SNR 3 Calls"
  },
  {
    "objectID": "content/BaleenWhales/Slides/methodsforloggingbaleenwhales.html#examples-of-bbad-recordings",
    "href": "content/BaleenWhales/Slides/methodsforloggingbaleenwhales.html#examples-of-bbad-recordings",
    "title": "Methods for Logging Baleen Whales SWFSC",
    "section": "Examples of B(bad) Recordings",
    "text": "Examples of B(bad) Recordings"
  },
  {
    "objectID": "content/BaleenWhales/Slides/methodsforloggingbaleenwhales.html#examples-of-ggood-recordings",
    "href": "content/BaleenWhales/Slides/methodsforloggingbaleenwhales.html#examples-of-ggood-recordings",
    "title": "Methods for Logging Baleen Whales SWFSC",
    "section": "Examples of G(good) Recordings",
    "text": "Examples of G(good) Recordings\n\n\n\n\nBack to Methods"
  },
  {
    "objectID": "content/ToothedWhales/NBHF-Detection.html",
    "href": "content/ToothedWhales/NBHF-Detection.html",
    "title": "NBHF",
    "section": "",
    "text": "Pamguard v.2.02.09 (https://www.pamguard.org/) is used to run click detector on full bandwidth data (384 kHz sample rate)\nData is high-pass filtered at 100 kHz with a click detector (12 dB threshold) \nPamguard v2.02.09f (public release expected to be available in early 2024) is used to reclassify clicks\n\nClick detections are classified within Pamguard based on peak frequency\nThe Matched Template Classifier module evaluates the similarity of each click detection to known templates\n\nPotential acoustic events are automatically defined in R\nPAMpal is used to calculate features of click detections in each event",
    "crumbs": [
      "Toothed Whales",
      "NBHF"
    ]
  },
  {
    "objectID": "content/ToothedWhales/NBHF-Detection.html#methods-summary",
    "href": "content/ToothedWhales/NBHF-Detection.html#methods-summary",
    "title": "NBHF",
    "section": "",
    "text": "Pamguard v.2.02.09 (https://www.pamguard.org/) is used to run click detector on full bandwidth data (384 kHz sample rate)\nData is high-pass filtered at 100 kHz with a click detector (12 dB threshold) \nPamguard v2.02.09f (public release expected to be available in early 2024) is used to reclassify clicks\n\nClick detections are classified within Pamguard based on peak frequency\nThe Matched Template Classifier module evaluates the similarity of each click detection to known templates\n\nPotential acoustic events are automatically defined in R\nPAMpal is used to calculate features of click detections in each event",
    "crumbs": [
      "Toothed Whales",
      "NBHF"
    ]
  },
  {
    "objectID": "content/ToothedWhales/NBHF-Detection.html#step-by-step-instructions",
    "href": "content/ToothedWhales/NBHF-Detection.html#step-by-step-instructions",
    "title": "NBHF",
    "section": "Step-by-Step Instructions",
    "text": "Step-by-Step Instructions\n\nRun echolocation click detector\n\nDefine location to save database and binary files\nDefine array configuration (hydrophone sensitivity and separation)\nSave configuration file with a descriptive filename\nPress Run\n\n\n\nReclassify clicks with click classifiers and matched template classifier\n\nImport Matched Template Classification module and Click Detector from NBHF_ClickClassifiers_and_MTC.psfx found in content/ToothedWhales/Pamguard settings directory\n\nClick classifiers are saved within the Click Detector module in the default NBHF_ClickClassifiers_and_MTC configuration file. They are also saved as individual .pgccs files within content/ToothedWhales/Click Classifiers/NBHF directory.\nIn the Pamguard File Menu, select “Import PAMGuard Modules”\nFor Click Detector, select “Replace existing Click Detector” and for Match Template Classifier, select “Import as new module”\n\nReclassify clicks with NBHF click classifiers\n\nIn the Pamguard Click Classifier menu, select “Reanalyse Clicks”\n\nSelect “All Data”, tick the “Delete old database entries” box, and tick the “Reclassify Clicks” box. Add a note “Reclassify based on NBHF peak frequencies”. Then click “Start”\n\nReclassify clicks for Matched Template Classifier\n\nIn the Pamguard Settings menu, select “Matched Template Classifier” and “Reclassify clicks”\n\nSelect “All Data”, tick the “Delete old database entries” box, and tick the “Matched Template Classifier” box. Add a note “Reanalyze based on NBHF MTC”. Then click “Start”\n\nWhen finished, save data and close Pamguard\n\n\n\n\nAutomatically define potential acoustic events in R\nFour thresholds are used to identify potential NBHF events, including “Pd_1” and “Pd_2” for Dall’s porpoise, “Pp” for Harbor porpoise, and “Ksp” for Kogia. Template thresholds: Pd_1=0.45, Pd_2=0.45, Pp=0.6, Ksp=0.45. These click templates were generated from acoustic encounters with known species. Thresholds were established in an iterative process to ensure no high quality acoustic events were missed.\nThe matchTemplateScript_NBHF.R script is used to identify potential NBHF events, add them to a database, and then generate an acoustic study using the PAMpal R package.\nEvents are automatically defined when the following conditions are met\n\n3 or more clicks exceed the MTC thresholds within 120 seconds\nEvents have a maximum duration of 120 seconds\n\n\n\nPredict species classification using BANTER model\n\n\nReview labels of low-scoring events",
    "crumbs": [
      "Toothed Whales",
      "NBHF"
    ]
  },
  {
    "objectID": "content/ToothedWhales/BeakedWhales-IDGuide.html",
    "href": "content/ToothedWhales/BeakedWhales-IDGuide.html",
    "title": "Beaked Whale ID Guide",
    "section": "",
    "text": "This guide serves as a living document, with the intention to update as more information is learned. To recommend an update or to open a discussion, submit an ‘Issue’ with a useful title and explanation. Go to this link [https://github.com/SAEL-SWFSC/adrift-analysis-methods/issues] to create an Issue, and use the BW-ID label for the issue.\nNote: IPI= inter-pulse interval, PPS= pulses per sec\n\n\n\nPeaks: 32-40 kHz, 22-24 kHz and ~18 kHz\nNull: Strong null at ~27 kHz\nIPI: 0.3-0.5 sec\nPPS: 2-3\n\nUpsweep usually evident. Wigner plots shows a “kickstand” (downsweep appearing after the upsweep). Sometimes this kickstand can just appear as a dot. At great range, the 18 and 22 kHz peaks may be higher than the 32-40 kHz peak and the Wigner can just show the downsweep.\nCitations:\n\n\n\n\n\n\nPeak: 15-16 kHz, 25-26 kHz, and, sometimes, 9 kHz and 35-45 kHz\nNull: NA\nIPI:0.20-0.25 sec\nPPS:4-5\n\nLow frequency click, often with multiple peaks. Upsweep is sometimes present, but pulses will look pretty flat on this scale. Can produce dolphin-like clicks as well as these longer pulses. Clicks can come from above the hydrophone.\n\n\n\n\n\n\nPeak:43 kHz\nNull: NA\nIPI:~0.22\nPPS:4-5\n\nSome higher peaks may be evident if the animal is close. The left limb declines less steeply than with BW46. Wigner is “crescent moon” shaped and lower limb, if present is strongly upswept.\n\n\nBW43 template (gray) and BW43 click from Baumann and Pickering (blue, pers. comm.)\nPeak and slope to the left of peak match well. Slope to the right of peak is much broader, perhaps reflecting proximity or hydrophone differences. Differences in Wigner plots are likely due to scaling differences. [Source: SOCAL41N_DL29_110122_175230.x_0000.wav]\n\n\n\n\n\n\nPeak: 44-48 kHz\nNull: NA\nIPI: 0.09\nPPS: 10-11\n\nPeak at about 46kHz (cyan and tan) shown on top of BW43 (gray). Notice how left slope in frequency spectrum declines more steeply than BW43, even when the peaks are similar (dark blue). The right slope is more variable for both types, but is less steep than the left slope.\n\nFrequency has very steeply declining slope to the left of peak. Right slope declines less steeply and may show higher peaks. Wigner shows “sorting cap”. The lower branch of the Wigner (if present) is nearly horizontal.\n\n\n\nSome pulses show very strong higher peak at about 75 kHz in addition to a distinct lower peak at about 50 kHz. Some signals (presumable closer or more on-axis) show a strong peak at 80 kHz, a second peak at 52 kHz, and a strong null at about 62 kHz. These may appear in the same event as 44-48kHz pulses (see above). No evidence of “sorting hat” in Wigner.\n\n\nAgain two peaks (green, same group as above). In this case, the lower peak is loudest. Inconspicuous “sorting hat” look to wigner.\n\n\n\n\n\n\nPeak:36 kHz\nNull: NA\nIPI:0.25-0.33\nPPS:3-4\n\nPeak frequency is ~36kHz (similar to Ziphius) but with a very steep decline in amplitudes at lower frequencies (left of the peak). This very clear one shows a secondary peak at 25 kHz, but that is 20dB below the peak and is not likely to be seen in a lower SNR signal. Wigner plot is slightly concave upward, with no sign of “kickstand”.\n\n \n\n\n\n\nPeak:34kHz, 50 kHz\nNull: 37kHz\nIPI: 0.125-0.166\nPPS: 6-8\n\nBW37V template (green) shows two distinct peaks at about 34 kHz and 50 kHz, with a strong null (valley) at 37kHz. Note: earlier versions may have identified these as BW39V; once the data was corrected for the frequency response of the hydrophone, the null was found to be at 37kHz.\n\n\n\n\n\n\nPeak: 70kHz\nNull: NA\nIPI: 0.12\nPPS: 8\nBW70 template (cyan) shows a peak at 70 kHz. Slope to the left of the peak is steeper than to the right. Upsweep in the Wigner plot. [Source is SIO, Baumann & Pickering pers. comm., GofCA4A4_051217_234230.x_1114.wav]\n\n\n\n\n\nPeak: 60-65 kHz\nNull: NA\nIPI: 0.127\nPPS: 8\nVery long click with very long frequency sweep and a peak frequency of about 60-65 kHz. Signals may come from above the hydrophones.\n\n\n\n\nPeak: ~26kHz\nNull: NA\nIPI: 0.27-0.40s\nPPS: 3-4\nPulses are low-frequency, with peak at ~26 kHz.\n\n \n\n\n\n\n\nWas above hydrophone. May be alternate part of the beam pattern of a BW46. Wigners were variable and odd looking. Some were almost circular. Need to look for others.\n\n\n\n\n\nMaybe M. densitrostris, but no evidence of an upsweep and signal was relatively short.\n\n\n\n\n\nLow-frequency click, typically &lt; 12 kHz peak. IPI= 0.4-1.0, PPS=1-2.",
    "crumbs": [
      "Toothed Whales",
      "Beaked Whale ID Guide"
    ]
  },
  {
    "objectID": "content/ToothedWhales/BeakedWhales-IDGuide.html#introduction",
    "href": "content/ToothedWhales/BeakedWhales-IDGuide.html#introduction",
    "title": "Beaked Whale ID Guide",
    "section": "",
    "text": "This guide serves as a living document, with the intention to update as more information is learned. To recommend an update or to open a discussion, submit an ‘Issue’ with a useful title and explanation. Go to this link [https://github.com/SAEL-SWFSC/adrift-analysis-methods/issues] to create an Issue, and use the BW-ID label for the issue.\nNote: IPI= inter-pulse interval, PPS= pulses per sec\n\n\n\nPeaks: 32-40 kHz, 22-24 kHz and ~18 kHz\nNull: Strong null at ~27 kHz\nIPI: 0.3-0.5 sec\nPPS: 2-3\n\nUpsweep usually evident. Wigner plots shows a “kickstand” (downsweep appearing after the upsweep). Sometimes this kickstand can just appear as a dot. At great range, the 18 and 22 kHz peaks may be higher than the 32-40 kHz peak and the Wigner can just show the downsweep.\nCitations:\n\n\n\n\n\n\nPeak: 15-16 kHz, 25-26 kHz, and, sometimes, 9 kHz and 35-45 kHz\nNull: NA\nIPI:0.20-0.25 sec\nPPS:4-5\n\nLow frequency click, often with multiple peaks. Upsweep is sometimes present, but pulses will look pretty flat on this scale. Can produce dolphin-like clicks as well as these longer pulses. Clicks can come from above the hydrophone.\n\n\n\n\n\n\nPeak:43 kHz\nNull: NA\nIPI:~0.22\nPPS:4-5\n\nSome higher peaks may be evident if the animal is close. The left limb declines less steeply than with BW46. Wigner is “crescent moon” shaped and lower limb, if present is strongly upswept.\n\n\nBW43 template (gray) and BW43 click from Baumann and Pickering (blue, pers. comm.)\nPeak and slope to the left of peak match well. Slope to the right of peak is much broader, perhaps reflecting proximity or hydrophone differences. Differences in Wigner plots are likely due to scaling differences. [Source: SOCAL41N_DL29_110122_175230.x_0000.wav]\n\n\n\n\n\n\nPeak: 44-48 kHz\nNull: NA\nIPI: 0.09\nPPS: 10-11\n\nPeak at about 46kHz (cyan and tan) shown on top of BW43 (gray). Notice how left slope in frequency spectrum declines more steeply than BW43, even when the peaks are similar (dark blue). The right slope is more variable for both types, but is less steep than the left slope.\n\nFrequency has very steeply declining slope to the left of peak. Right slope declines less steeply and may show higher peaks. Wigner shows “sorting cap”. The lower branch of the Wigner (if present) is nearly horizontal.\n\n\n\nSome pulses show very strong higher peak at about 75 kHz in addition to a distinct lower peak at about 50 kHz. Some signals (presumable closer or more on-axis) show a strong peak at 80 kHz, a second peak at 52 kHz, and a strong null at about 62 kHz. These may appear in the same event as 44-48kHz pulses (see above). No evidence of “sorting hat” in Wigner.\n\n\nAgain two peaks (green, same group as above). In this case, the lower peak is loudest. Inconspicuous “sorting hat” look to wigner.\n\n\n\n\n\n\nPeak:36 kHz\nNull: NA\nIPI:0.25-0.33\nPPS:3-4\n\nPeak frequency is ~36kHz (similar to Ziphius) but with a very steep decline in amplitudes at lower frequencies (left of the peak). This very clear one shows a secondary peak at 25 kHz, but that is 20dB below the peak and is not likely to be seen in a lower SNR signal. Wigner plot is slightly concave upward, with no sign of “kickstand”.\n\n \n\n\n\n\nPeak:34kHz, 50 kHz\nNull: 37kHz\nIPI: 0.125-0.166\nPPS: 6-8\n\nBW37V template (green) shows two distinct peaks at about 34 kHz and 50 kHz, with a strong null (valley) at 37kHz. Note: earlier versions may have identified these as BW39V; once the data was corrected for the frequency response of the hydrophone, the null was found to be at 37kHz.\n\n\n\n\n\n\nPeak: 70kHz\nNull: NA\nIPI: 0.12\nPPS: 8\nBW70 template (cyan) shows a peak at 70 kHz. Slope to the left of the peak is steeper than to the right. Upsweep in the Wigner plot. [Source is SIO, Baumann & Pickering pers. comm., GofCA4A4_051217_234230.x_1114.wav]\n\n\n\n\n\nPeak: 60-65 kHz\nNull: NA\nIPI: 0.127\nPPS: 8\nVery long click with very long frequency sweep and a peak frequency of about 60-65 kHz. Signals may come from above the hydrophones.\n\n\n\n\nPeak: ~26kHz\nNull: NA\nIPI: 0.27-0.40s\nPPS: 3-4\nPulses are low-frequency, with peak at ~26 kHz.\n\n \n\n\n\n\n\nWas above hydrophone. May be alternate part of the beam pattern of a BW46. Wigners were variable and odd looking. Some were almost circular. Need to look for others.\n\n\n\n\n\nMaybe M. densitrostris, but no evidence of an upsweep and signal was relatively short.\n\n\n\n\n\nLow-frequency click, typically &lt; 12 kHz peak. IPI= 0.4-1.0, PPS=1-2.",
    "crumbs": [
      "Toothed Whales",
      "Beaked Whale ID Guide"
    ]
  },
  {
    "objectID": "content/ToothedWhales/SpermWhales-Detection.html",
    "href": "content/ToothedWhales/SpermWhales-Detection.html",
    "title": "Sperm Whales",
    "section": "",
    "text": "Triton software is used for the following:\n\nAcoustic data is decimated to 48 kHz sample rate\nLong-term spectral averages (LTSAs) are calculated with a X Hz, X second resolution\nThe start and end times of sperm whale echolocation clicks are identified by manually scanning LTSAs in 1 hour windows\nIdentify periods of vessel noise or buoy self-noise which could mask sperm whale echolocation",
    "crumbs": [
      "Toothed Whales",
      "Sperm Whales"
    ]
  },
  {
    "objectID": "content/ToothedWhales/SpermWhales-Detection.html#methods-summary",
    "href": "content/ToothedWhales/SpermWhales-Detection.html#methods-summary",
    "title": "Sperm Whales",
    "section": "",
    "text": "Triton software is used for the following:\n\nAcoustic data is decimated to 48 kHz sample rate\nLong-term spectral averages (LTSAs) are calculated with a X Hz, X second resolution\nThe start and end times of sperm whale echolocation clicks are identified by manually scanning LTSAs in 1 hour windows\nIdentify periods of vessel noise or buoy self-noise which could mask sperm whale echolocation",
    "crumbs": [
      "Toothed Whales",
      "Sperm Whales"
    ]
  },
  {
    "objectID": "content/ToothedWhales/SpermWhales-Detection.html#step-by-step-instructions",
    "href": "content/ToothedWhales/SpermWhales-Detection.html#step-by-step-instructions",
    "title": "Sperm Whales",
    "section": "Step-by-Step Instructions",
    "text": "Step-by-Step Instructions\n\nDecimation of acoustic data\nMost ADRIFT acoustic data is recorded at sampling rates of 384 kHz, however sperm whale echolocation clicks contain energy between 400 Hz to 30 kHz. To reduce processing time and data storage requirements, full bandwidth data is decimated to a sample rate of 48 kHz using a decimation factor of 8 (384,000/48,000=8).\n\nIn the Triton “Control” window, select the Tools menu and choose to “Decimate All WAV Files in Directory”\n\nYou will be prompted to choose a folder of WAV files, and then define the appropriate decimation factor. For example, to decimate from 384 kHz to 48 kHz, use a decimation factor of 8.\nThen define a folder to save the new, decimated WAV files.\nThe decimation process will start automatically and show a progress bar. When the decimation is complete, the progress bar will disappear. Depending on the total number of files and the required decimation factor, this process may take a few hours.\n\n\n\nGenerate Long Term Spectral Average (LTSA)\nSee methods in “Data Prep” section. Use 5 s 200 Hz resolution.\n\n\nManually log sperm whale acoustic events\nStart Triton Logger remora\n\nLaunch Triton within Matlab. Open the LTSA for the data you want to analyze.\nIn the Triton “Control” window, select the Remoras menu, choose Logger and then start a new log. You will to re-start Triton if this is the first instance of using the Logger remora. See more info on Triton Remoras on the Marine Bioacoustic Research wiki.\n\nLog start and end times of sperm whale acoustic events\nSperm whales (Physeter macrocephalus) produce echolocation clicks which can be easily identified by their distinct frequency content and high amplitude signal observable in the LTSA and spectrogram (Worthington and Schevill 1957; Watkins and Schevill 1977; Goold 1999;, B. Møhl et al. 2000; Bertel Møhl et al. 2003; Madsen, Wahlberg, and Møhl 2002).\nA trained analyst viewed 1 h windows of long-term spectral averages (LTSA; Wiggins and Hildebrand (2007); 5 s time average, 100 Hz frequency bins). Once sperm whale clicks were identified in the LTSA, 10 s spectrograms were used to confirm species identification (Figure 1). LTSAs and spectrograms were scanned with a brightness of 60 and a contrast of 180 for consistency across deployments. An encounter was defined as a series of clicks separated by no more than 30 min from other clicks. This time frame was chosen to match the typical echolocation production time during an average sperm whale dive cycle (Watwood et al. 2006). The start and end times of all encounters were noted, and these start and end times were used for further analysis.\nOpportunistic detections of slow clicks were also logged. These clicks have longer interclick intervals, a lower frequency emphasis around 2-4 kHz, and a longer duration (Figure 2) (Mullins, Whitehead, and Weilgart 1988; Weilgart and Whitehead 1988; Jaquet, Dawson, and Douglas 2001; Madsen, Wahlberg, and Møhl 2002).\nWe assumed no signals were mistaken for sperm whales because all LTSA detections were visually verified. We also assumed negligible missed detections given the characteristics of sperm whale echolocation clicks that make them easy to distinguish from other odontocete species, particularly their frequency content.\n\n\n\n\n\n\nFigure 1: Example of sperm whale echolocation clicks in the 1 hr LTSA (top) and 10 s spectrogram (bottom).\n\n\n\n\n\n\n\n\n\nFigure 2: Example of sperm whale slow clicks in the 1 hr LTSA (top) and 20 s spectrogram (bottom).\n\n\n\n\n\nIdentify potential masking for sperm whale echolocation\nSperm whale clicks can be masked by the impulsive signals from ship propeller cavitation or high amplitude ambient noise (rain, wind, etc.). Times with ship or ambient noise that masked any potential sperm whale clicks were considered times with no effort since analysts were unable to determine sperm whale presence (Figure 3). Ships were logged as either being broadband or narrowband/low frequency (see details of ship logging in soundscape methods for more details). Narrowband/low frequency ships were fainter and did not mask sperm whale detections and were considered times with logging effort.\n\n\n\n\n\n\nFigure 3: Example of potential masking of sperm whale echolocation by ambient noise.\n\n\n\n##Add sub-section about IPI/ICI analysis (not useful for duty-cycled data; Could be useful to apply on continuous data)",
    "crumbs": [
      "Toothed Whales",
      "Sperm Whales"
    ]
  },
  {
    "objectID": "content/ToothedWhales/BeakedWhales-Detection.html",
    "href": "content/ToothedWhales/BeakedWhales-Detection.html",
    "title": "Beaked Whales",
    "section": "",
    "text": "Data is whitened by applying 1st order, high-pass filter at 80 kHz, then decimated to 288 kHz\nClicks are detected (pre-filter at 10 kHz, detector threshold 12 dB) with multiple click classifiers, and then the click template classification module is used to assign correlation scores to click templates from the following click types: ZC, BB, MD, MS, MC (formerly BW37V), BWC, BW43. \nEvents and species ID are manually defined and bearing angles are manually corrected in Pamguard Viewer\nPAMpal is used to calculate features of click detections",
    "crumbs": [
      "Toothed Whales",
      "Beaked Whales"
    ]
  },
  {
    "objectID": "content/ToothedWhales/BeakedWhales-Detection.html#methods-summary",
    "href": "content/ToothedWhales/BeakedWhales-Detection.html#methods-summary",
    "title": "Beaked Whales",
    "section": "",
    "text": "Data is whitened by applying 1st order, high-pass filter at 80 kHz, then decimated to 288 kHz\nClicks are detected (pre-filter at 10 kHz, detector threshold 12 dB) with multiple click classifiers, and then the click template classification module is used to assign correlation scores to click templates from the following click types: ZC, BB, MD, MS, MC (formerly BW37V), BWC, BW43. \nEvents and species ID are manually defined and bearing angles are manually corrected in Pamguard Viewer\nPAMpal is used to calculate features of click detections",
    "crumbs": [
      "Toothed Whales",
      "Beaked Whales"
    ]
  },
  {
    "objectID": "content/DataArchive/NCEI.html",
    "href": "content/DataArchive/NCEI.html",
    "title": "NCEI",
    "section": "",
    "text": "Most of the following information can be found in the Passive Packer Manual. This information is summarized from the manual with ADRIFT specific directions for various Passive Packer guidelines and fields. The following steps were put together using Passive Packer v.4.0.2.\n\n\n\nNCEI Passive Acoustic Data Viewer\nPassive Packer Manual\nAdditional Archive Guidelines\n\n\n\n\n\n\nOnly use Western Digital or Seagate Drives\n\nWe bought 4 20TB WD Elements Desktop Hard Drives for PASCAL, CCES, and ADRIFT\n\nData can be packaged directly from its home directory to the destination external hard drive\nAll data and the metadata files created by Passive Packer must fit on the destination drive, ensure there is ample space on drive to reduce the risk of the program crashing\n\n\n\n\nInclude the organization and project name without spaces in the hard drive name\n\nExample: SWFSC_ADRIFT_DRIVE\n\n\n\n\nLabel drive with the following information easily visible\n\nPackagers full name\nYour organization\nProject Name\nExample: Kourtney Burger, SWFSC, ADRIFT\n\n\n\n\n\nThe goal is to automate the Passive Packer process as much as possible. Currently, these guidelines will help with manual data entry.\n\n\n\nTry exporting Tethys queries and import data into Passive Packer\nModify Anne’s Tethys deployment spreadsheet script to pull necessary data from deployment details and import it to Passive Packer database. This will auto-fill most fields when Passive Packer is opened, allowing for less manual entry. \n\n\n\n\n\n\nDownload software from Passive Packer Website and follow the ‘Getting Started’ directions\nSee Passive Packer Manual for introduction to software and guidelines on packaging other passive acoustics data, including detections and moored deployments\nNote: The majority of the information required by Passive Packer can be found in the Deployment Details spreadsheet\n\n\n\n\n\n\n?: Opens Passive Packer Manual\nHide Records: Opens the package record show/hide dialog box. Previous packages records with show selected will be displayed in the Select Existing Record drop down menu\nClear Form: Clears all form fields on all tabs\nStop Packaging: Stops the packaging process at its current point\nSave For Later: Saves entered data for later use. Allows the user to continue working on packaging their data at a later date. This button should be routinely clicked to minimize data loss in case Passive Packer crashes\nPackage Data: Starts the packaging process\n\n\n\n\n\n\nProjects: input or select from drop down ADRIFT, CCES, PASCAL, or other applicable project name\nSite or Cruise: input cruise name (drifting deployments do not have set sites)\nDeployment ID: Input 3 digit deployment number\nPackage destination: path to external hard drive\nDataset Type: Audio (unless packaging other types of acoustic data, see manual for directions)\nDeployment Type: Mobile Marine\nPublic Release Date: For SWFSC ADRIFT project, always list at least 1 year after data were collected\nDataset Packager: Your name, use ‘Create/Edit People’ if you are not on the drop down menu\nExport JSON File & Export Records: Once all data fields have been filled in, export the file and save it to you metadata folder\nSelect existing dataset and ‘Generate Dataset Name’: use drop down to select data you saved for later or fill in all above information and click ‘Generate Dataset Name’ to create a new dataset entry\n\n\n\n\n\n\nDeployment Title: Full name of project/ dataset\n\nExample: For CCES write ’California Current Ecosystems Survey - Passive Acoustics Survey\n\nDeployment Purpose: Description of the purpose of the deployment/ dataset. Stays the same for each project, use information from reports for past projects\nDeployment Description: Information on why data were collected, details for future data users, and anything special that might affect data usefulness for other analyses. Stays the same for each project, use information from reports for past projects\nPath to documentation files: Path to directory with reports or other documentation files. Files can be added after packaging is complete using Update Bag function \nAlternate site name and Alternate deployment name: Leave blank for ADRIFT\n\n\n\n\n\n\nPlatform: Drifter\nInstrument type: ST4300, ST640, or other instrument\nInstrument ID: 4 digit soundtrap ID number\nDeployment Time: time of deployment (UTC)\nRecovery Time: time of recovery (UTC)\nAudio Start Time: start time of first audio file (UTC)\nAudio End Time: end time of last audio file(UTC)\nPath to audio files: path to wav file directory\nDeployment comments: From deployment details, any comments that may be useful to future users and analysis. No quality comments should be included here\nSampling Details, Data Quality, Sensors: See next slides\n\n\n\n\n\n\nChannel Time & all other time field: Should auto-fill based on ‘Audio Start Time’ and ‘Audio End Time’ in Dataset Details tab. Edit as necessary\nSensor Number: Should match number used in Sensor Details window, change sensor number if duplicating channels\nSample Rate (kHz): sampling rate set in soundtrap deployment window, should be 384 for ADRIFT\nSample Bits: 16 for ADRIFT\nGain (dB) or Gain (rel):\nDuration and Interval: Fill in duty cycle information or check continuous box. Note: if set to a continuous cycle (i.e. 6/6) do not check continuous, fill in duration and interval both as 6\nAdd Sample Rate, Gain, and Duty Cycle as needed. Should only be different if recorder malfunctioned or was set to record with different settings throughout deployment\nUse New Channel or Duplicate Channel to add channels as needed. Should have at least 2 for ADRIFT, include bad channels \n\n\n\n\n\nFor ADRIFT an overall deployment data quality entry will be added and a detailed noise log will be attached\n\nQuality Analyst: select who determined the data quality, create/edit people as needed\nSelect Quality Level: select overall deployment data quality from drop down\nFrequency Range: input minimum and maximum frequency for that data quality level\nTime will auto-fill from Dataset Details tab\nComments: include any comments about data quality here\nChannels: for ADRIFT we only analyze channel 1, change as needed\nAdd quality entries and update times as needed\nAdditional Quality Information: Fill in objectives, method, and description of quality assessment for future users and analysts\n\n\n\n\n\n\n\nAdd new sensor for each channel, 2 CH for ADRIFT\n\nSensor Number: match sensor number from Sampling Details Window\nSensor ID: Hydrophone Serial Number\nSensor Name: type of hydrophone (HTI-99-HF, HTI-92-WB, or HTI-96-MIN)\nSensor Position: leave X and Y blank, Z for sensor 1 is deployment depth, Z for other sensors is the deployment depth plus the distance between sensor 1 and sensor x (1 is -100, 2 is -105)\nHydrophone ID:\nPreamp ID: leave blank for ADRIFT\nSensor Description: Any additional information about hydrophone\n\n\n\n\n\nSensor Number: 3 (if 2 audio sensors were added above)\nSensor ID: depth sensor serial number (i.e. U-15771)\nSensor Name: Sensus Ultra\nSensor Position: Deployment depth (-100)\nSensor Description: Any additional information about depth sensor\n\n\n\n\nAdd new sensor if 2 GPS units were used (i.e. SPOT)\n\nSensor Number: 4 (if 2 audio sensors and depth sensor were added)\nSensor ID: GPS ID (7 digit number, 3391082 or 0-4554502)\nSensor Name: GPS name (SO-001 or Spot Letter)\nSensor Position: +1 (above sea level)\nSensor Type: GPS\nProperties: Leave blank\nSensor Description: Any additional information about GPS\n\nAdd other sensors as needed\n\n\n\n\n\n\nVessel: Name of deployment vessel\nIHO Sea Area: North Pacific Ocean\nPath to navigation / position files: select GPS csv\nDescription of location derivation:\n\n\n\n\n\n\nCalibration State:\nHydrophone Sensitivity (dB):\nFrequency Range (Hz): (i.e. 20-5000)\nGain (dB):\nPath to Calibration Documents:\nCalibration Description: Enter calibration methods and any other relevant calibration information\n\n\n\n\n\n\nScientists: List PI and Chief Scientist for each project/deployment (PASCAL - Shannon Rankin & Jennifer McCullough, CCES - Shannon Rankin and Anne Simonis, ADRIFT - Shannon Rankin & Deployment Details Personnel Column)\nSource Organizations: SWFSC\nFunding Organization: Always list SWFSC, check acknowledgements in past reports, ADRIFT - BOEM\nCreate/Edit people and organizations as needed\n\n\n\n\n\n\nPath to temperature data files: directory with temp files from soundtrap or temperature sensor\nPath to observational data files: only include for opportunistic recordings with observation notes (species, behavior, time, etc.)\nPath to other files you wish to submit: accelerometer and depth data\n\n\n\nSee Passive Packer manual for Additional Information and Warning Message Guidelines",
    "crumbs": [
      "Data Archive",
      "Archive",
      "NCEI"
    ]
  },
  {
    "objectID": "content/DataArchive/NCEI.html#ncei-passive-packer-metadata",
    "href": "content/DataArchive/NCEI.html#ncei-passive-packer-metadata",
    "title": "NCEI",
    "section": "",
    "text": "Most of the following information can be found in the Passive Packer Manual. This information is summarized from the manual with ADRIFT specific directions for various Passive Packer guidelines and fields. The following steps were put together using Passive Packer v.4.0.2.\n\n\n\nNCEI Passive Acoustic Data Viewer\nPassive Packer Manual\nAdditional Archive Guidelines\n\n\n\n\n\n\nOnly use Western Digital or Seagate Drives\n\nWe bought 4 20TB WD Elements Desktop Hard Drives for PASCAL, CCES, and ADRIFT\n\nData can be packaged directly from its home directory to the destination external hard drive\nAll data and the metadata files created by Passive Packer must fit on the destination drive, ensure there is ample space on drive to reduce the risk of the program crashing\n\n\n\n\nInclude the organization and project name without spaces in the hard drive name\n\nExample: SWFSC_ADRIFT_DRIVE\n\n\n\n\nLabel drive with the following information easily visible\n\nPackagers full name\nYour organization\nProject Name\nExample: Kourtney Burger, SWFSC, ADRIFT\n\n\n\n\n\nThe goal is to automate the Passive Packer process as much as possible. Currently, these guidelines will help with manual data entry.\n\n\n\nTry exporting Tethys queries and import data into Passive Packer\nModify Anne’s Tethys deployment spreadsheet script to pull necessary data from deployment details and import it to Passive Packer database. This will auto-fill most fields when Passive Packer is opened, allowing for less manual entry. \n\n\n\n\n\n\nDownload software from Passive Packer Website and follow the ‘Getting Started’ directions\nSee Passive Packer Manual for introduction to software and guidelines on packaging other passive acoustics data, including detections and moored deployments\nNote: The majority of the information required by Passive Packer can be found in the Deployment Details spreadsheet\n\n\n\n\n\n\n?: Opens Passive Packer Manual\nHide Records: Opens the package record show/hide dialog box. Previous packages records with show selected will be displayed in the Select Existing Record drop down menu\nClear Form: Clears all form fields on all tabs\nStop Packaging: Stops the packaging process at its current point\nSave For Later: Saves entered data for later use. Allows the user to continue working on packaging their data at a later date. This button should be routinely clicked to minimize data loss in case Passive Packer crashes\nPackage Data: Starts the packaging process\n\n\n\n\n\n\nProjects: input or select from drop down ADRIFT, CCES, PASCAL, or other applicable project name\nSite or Cruise: input cruise name (drifting deployments do not have set sites)\nDeployment ID: Input 3 digit deployment number\nPackage destination: path to external hard drive\nDataset Type: Audio (unless packaging other types of acoustic data, see manual for directions)\nDeployment Type: Mobile Marine\nPublic Release Date: For SWFSC ADRIFT project, always list at least 1 year after data were collected\nDataset Packager: Your name, use ‘Create/Edit People’ if you are not on the drop down menu\nExport JSON File & Export Records: Once all data fields have been filled in, export the file and save it to you metadata folder\nSelect existing dataset and ‘Generate Dataset Name’: use drop down to select data you saved for later or fill in all above information and click ‘Generate Dataset Name’ to create a new dataset entry\n\n\n\n\n\n\nDeployment Title: Full name of project/ dataset\n\nExample: For CCES write ’California Current Ecosystems Survey - Passive Acoustics Survey\n\nDeployment Purpose: Description of the purpose of the deployment/ dataset. Stays the same for each project, use information from reports for past projects\nDeployment Description: Information on why data were collected, details for future data users, and anything special that might affect data usefulness for other analyses. Stays the same for each project, use information from reports for past projects\nPath to documentation files: Path to directory with reports or other documentation files. Files can be added after packaging is complete using Update Bag function \nAlternate site name and Alternate deployment name: Leave blank for ADRIFT\n\n\n\n\n\n\nPlatform: Drifter\nInstrument type: ST4300, ST640, or other instrument\nInstrument ID: 4 digit soundtrap ID number\nDeployment Time: time of deployment (UTC)\nRecovery Time: time of recovery (UTC)\nAudio Start Time: start time of first audio file (UTC)\nAudio End Time: end time of last audio file(UTC)\nPath to audio files: path to wav file directory\nDeployment comments: From deployment details, any comments that may be useful to future users and analysis. No quality comments should be included here\nSampling Details, Data Quality, Sensors: See next slides\n\n\n\n\n\n\nChannel Time & all other time field: Should auto-fill based on ‘Audio Start Time’ and ‘Audio End Time’ in Dataset Details tab. Edit as necessary\nSensor Number: Should match number used in Sensor Details window, change sensor number if duplicating channels\nSample Rate (kHz): sampling rate set in soundtrap deployment window, should be 384 for ADRIFT\nSample Bits: 16 for ADRIFT\nGain (dB) or Gain (rel):\nDuration and Interval: Fill in duty cycle information or check continuous box. Note: if set to a continuous cycle (i.e. 6/6) do not check continuous, fill in duration and interval both as 6\nAdd Sample Rate, Gain, and Duty Cycle as needed. Should only be different if recorder malfunctioned or was set to record with different settings throughout deployment\nUse New Channel or Duplicate Channel to add channels as needed. Should have at least 2 for ADRIFT, include bad channels \n\n\n\n\n\nFor ADRIFT an overall deployment data quality entry will be added and a detailed noise log will be attached\n\nQuality Analyst: select who determined the data quality, create/edit people as needed\nSelect Quality Level: select overall deployment data quality from drop down\nFrequency Range: input minimum and maximum frequency for that data quality level\nTime will auto-fill from Dataset Details tab\nComments: include any comments about data quality here\nChannels: for ADRIFT we only analyze channel 1, change as needed\nAdd quality entries and update times as needed\nAdditional Quality Information: Fill in objectives, method, and description of quality assessment for future users and analysts\n\n\n\n\n\n\n\nAdd new sensor for each channel, 2 CH for ADRIFT\n\nSensor Number: match sensor number from Sampling Details Window\nSensor ID: Hydrophone Serial Number\nSensor Name: type of hydrophone (HTI-99-HF, HTI-92-WB, or HTI-96-MIN)\nSensor Position: leave X and Y blank, Z for sensor 1 is deployment depth, Z for other sensors is the deployment depth plus the distance between sensor 1 and sensor x (1 is -100, 2 is -105)\nHydrophone ID:\nPreamp ID: leave blank for ADRIFT\nSensor Description: Any additional information about hydrophone\n\n\n\n\n\nSensor Number: 3 (if 2 audio sensors were added above)\nSensor ID: depth sensor serial number (i.e. U-15771)\nSensor Name: Sensus Ultra\nSensor Position: Deployment depth (-100)\nSensor Description: Any additional information about depth sensor\n\n\n\n\nAdd new sensor if 2 GPS units were used (i.e. SPOT)\n\nSensor Number: 4 (if 2 audio sensors and depth sensor were added)\nSensor ID: GPS ID (7 digit number, 3391082 or 0-4554502)\nSensor Name: GPS name (SO-001 or Spot Letter)\nSensor Position: +1 (above sea level)\nSensor Type: GPS\nProperties: Leave blank\nSensor Description: Any additional information about GPS\n\nAdd other sensors as needed\n\n\n\n\n\n\nVessel: Name of deployment vessel\nIHO Sea Area: North Pacific Ocean\nPath to navigation / position files: select GPS csv\nDescription of location derivation:\n\n\n\n\n\n\nCalibration State:\nHydrophone Sensitivity (dB):\nFrequency Range (Hz): (i.e. 20-5000)\nGain (dB):\nPath to Calibration Documents:\nCalibration Description: Enter calibration methods and any other relevant calibration information\n\n\n\n\n\n\nScientists: List PI and Chief Scientist for each project/deployment (PASCAL - Shannon Rankin & Jennifer McCullough, CCES - Shannon Rankin and Anne Simonis, ADRIFT - Shannon Rankin & Deployment Details Personnel Column)\nSource Organizations: SWFSC\nFunding Organization: Always list SWFSC, check acknowledgements in past reports, ADRIFT - BOEM\nCreate/Edit people and organizations as needed\n\n\n\n\n\n\nPath to temperature data files: directory with temp files from soundtrap or temperature sensor\nPath to observational data files: only include for opportunistic recordings with observation notes (species, behavior, time, etc.)\nPath to other files you wish to submit: accelerometer and depth data\n\n\n\nSee Passive Packer manual for Additional Information and Warning Message Guidelines",
    "crumbs": [
      "Data Archive",
      "Archive",
      "NCEI"
    ]
  },
  {
    "objectID": "content/DataArchive/NCEI.html#archive-to-ncei",
    "href": "content/DataArchive/NCEI.html#archive-to-ncei",
    "title": "NCEI",
    "section": "Archive to NCEI",
    "text": "Archive to NCEI\n\nArchive data and metadata to NCEI",
    "crumbs": [
      "Data Archive",
      "Archive",
      "NCEI"
    ]
  },
  {
    "objectID": "content/DataArchive/DataUpload.html",
    "href": "content/DataArchive/DataUpload.html",
    "title": "Data Upload",
    "section": "",
    "text": "All of the following files will be uploaded to the shared network drive, The Don\n\nUpload extracted SUD files (sud, log, wav, and accelerometer)\nUpload Depth Data to the metadata folder\nUpload GPS Data from the Driftwatch gps_csv folder to the metadata folder\nUpload Photos to metadata media folder\nUpload Videos to metadata media folder\nUpload Sightings Forms to metadata media folder\nUpload any additional metadata to metadata folder\n\nIncluding QAQC results",
    "crumbs": [
      "Data Archive",
      "Data Upload"
    ]
  },
  {
    "objectID": "content/DataArchive/DataUpload.html#don-metadata-upload",
    "href": "content/DataArchive/DataUpload.html#don-metadata-upload",
    "title": "Data Upload",
    "section": "",
    "text": "All of the following files will be uploaded to the shared network drive, The Don\n\nUpload extracted SUD files (sud, log, wav, and accelerometer)\nUpload Depth Data to the metadata folder\nUpload GPS Data from the Driftwatch gps_csv folder to the metadata folder\nUpload Photos to metadata media folder\nUpload Videos to metadata media folder\nUpload Sightings Forms to metadata media folder\nUpload any additional metadata to metadata folder\n\nIncluding QAQC results",
    "crumbs": [
      "Data Archive",
      "Data Upload"
    ]
  },
  {
    "objectID": "content/DataArchive/DataUpload.html#high-quality-photos-and-videos",
    "href": "content/DataArchive/DataUpload.html#high-quality-photos-and-videos",
    "title": "Data Upload",
    "section": "High Quality Photos and Videos",
    "text": "High Quality Photos and Videos\n\nSubmit any high quality photos/videos to Photo & Video Library",
    "crumbs": [
      "Data Archive",
      "Data Upload"
    ]
  },
  {
    "objectID": "content/DataArchive/TethysDetections.html",
    "href": "content/DataArchive/TethysDetections.html",
    "title": "Tethys - Detections",
    "section": "",
    "text": "Follow guidelines on the TethysSAEL repository on Anne’s github (requires user define inputs)",
    "crumbs": [
      "Data Archive",
      "Archive",
      "Tethys - Detections"
    ]
  },
  {
    "objectID": "content/DataArchive/TethysDetections.html#tethys-detection-worksheet",
    "href": "content/DataArchive/TethysDetections.html#tethys-detection-worksheet",
    "title": "Tethys - Detections",
    "section": "",
    "text": "Follow guidelines on the TethysSAEL repository on Anne’s github (requires user define inputs)",
    "crumbs": [
      "Data Archive",
      "Archive",
      "Tethys - Detections"
    ]
  },
  {
    "objectID": "content/DataArchive/TethysDetections.html#upload-detections-to-tethys",
    "href": "content/DataArchive/TethysDetections.html#upload-detections-to-tethys",
    "title": "Tethys - Detections",
    "section": "Upload Detections to Tethys",
    "text": "Upload Detections to Tethys\n\nSWFSC.Detections.Analyst.v1 sourcemap\nNOAA.NMFS.v4 species abbreviation",
    "crumbs": [
      "Data Archive",
      "Archive",
      "Tethys - Detections"
    ]
  },
  {
    "objectID": "content/DataArchive/OBIS.html",
    "href": "content/DataArchive/OBIS.html",
    "title": "OBIS",
    "section": "",
    "text": "*Need to check w/ Taiki about this",
    "crumbs": [
      "Data Archive",
      "Archive",
      "OBIS"
    ]
  },
  {
    "objectID": "content/DataArchive/OBIS.html#obis-archive-metadata",
    "href": "content/DataArchive/OBIS.html#obis-archive-metadata",
    "title": "OBIS",
    "section": "",
    "text": "*Need to check w/ Taiki about this",
    "crumbs": [
      "Data Archive",
      "Archive",
      "OBIS"
    ]
  }
]